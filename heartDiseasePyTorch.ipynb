{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split \n",
    "from torch.nn import functional as F  \n",
    "import torch.optim as optim\n",
    "from torchsummary import summary \n",
    "\n",
    " \n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as mplot\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import os\n",
    "import subprocess\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score, f1_score, precision_score, recall_score,  precision_recall_fscore_support\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    " \n",
    " # Convert to PyTorch tensors\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary \n",
    "\n",
    "\n",
    "\n",
    "import pickle \n",
    "import shap\n",
    "import lime\n",
    "from lime import lime_tabular\n",
    "import random\n",
    "import dalex as dx\n",
    "\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import pydotplus\n",
    "import seaborn as sns\n",
    "\n",
    "from tabulate import tabulate \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of fileData: (37079, 51)\n",
      "Column Headings: Index(['SEQN', 'Gender', 'Age', 'Annual-Family-Income',\n",
      "       'Ratio-Family-Income-Poverty', 'X60-sec-pulse', 'Systolic', 'Diastolic',\n",
      "       'Weight', 'Height', 'Body-Mass-Index', 'White-Blood-Cells',\n",
      "       'Lymphocyte', 'Monocyte', 'Eosinophils', 'Basophils', 'Red-Blood-Cells',\n",
      "       'Hemoglobin', 'Mean-Cell-Vol', 'Mean-Cell-Hgb-Conc.',\n",
      "       'Mean-cell-Hemoglobin', 'Platelet-count', 'Mean-Platelet-Vol',\n",
      "       'Segmented-Neutrophils', 'Hematocrit', 'Red-Cell-Distribution-Width',\n",
      "       'Albumin', 'ALP', 'AST', 'ALT', 'Cholesterol', 'Creatinine', 'Glucose',\n",
      "       'GGT', 'Iron', 'LDH', 'Phosphorus', 'Bilirubin', 'Protein', 'Uric.Acid',\n",
      "       'Triglycerides', 'Total-Cholesterol', 'HDL', 'Glycohemoglobin',\n",
      "       'Vigorous-work', 'Moderate-work', 'Health-Insurance', 'Diabetes',\n",
      "       'Blood-Rel-Diabetes', 'Blood-Rel-Stroke', 'CoronaryHeartDisease'],\n",
      "      dtype='object')\n",
      "Number of Records: 37079\n",
      "\n",
      "Number of Missing Values: 0\n",
      "Number of duplicate records removed: 0\n",
      "Shape of fileData: (37079, 51)\n",
      "Shape of fileData End: (37079, 51)\n",
      "\n",
      "\n",
      "columns of x:: 50 \n",
      "\n",
      " and features of X: Index(['SEQN', 'Gender', 'Age', 'Annual-Family-Income',\n",
      "       'Ratio-Family-Income-Poverty', 'X60-sec-pulse', 'Systolic', 'Diastolic',\n",
      "       'Weight', 'Height', 'Body-Mass-Index', 'White-Blood-Cells',\n",
      "       'Lymphocyte', 'Monocyte', 'Eosinophils', 'Basophils', 'Red-Blood-Cells',\n",
      "       'Hemoglobin', 'Mean-Cell-Vol', 'Mean-Cell-Hgb-Conc.',\n",
      "       'Mean-cell-Hemoglobin', 'Platelet-count', 'Mean-Platelet-Vol',\n",
      "       'Segmented-Neutrophils', 'Hematocrit', 'Red-Cell-Distribution-Width',\n",
      "       'Albumin', 'ALP', 'AST', 'ALT', 'Cholesterol', 'Creatinine', 'Glucose',\n",
      "       'GGT', 'Iron', 'LDH', 'Phosphorus', 'Bilirubin', 'Protein', 'Uric.Acid',\n",
      "       'Triglycerides', 'Total-Cholesterol', 'HDL', 'Glycohemoglobin',\n",
      "       'Vigorous-work', 'Moderate-work', 'Health-Insurance', 'Diabetes',\n",
      "       'Blood-Rel-Diabetes', 'Blood-Rel-Stroke'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "dataSetIndex = 4\n",
    "needToMakePictureOfTrees = 0\n",
    "''' ---------------------------------------------------------- '''\n",
    "dataSetFilePath = \"\"\n",
    "dataSetName = \"\"\n",
    "dataSetResultDirectory = \"./\"\n",
    "\n",
    "if(dataSetIndex == 0):\n",
    "    dataSetFilePath = \"./heartDisease/0_statLog_dataSet.csv\"\n",
    "    dataSetName = \"SateLog_DataSet\"\n",
    "elif (dataSetIndex == 1):\n",
    "    dataSetFilePath = \"./heartDisease/1_heart_statlog_cleveland_hungary_final.csv\"\n",
    "    dataSetName = \"ALL_StateLog_CleveLand_Hungary\"\n",
    "elif (dataSetIndex == 2):\n",
    "    dataSetFilePath = \"./heartDisease/2_cleveland.csv\"\n",
    "    dataSetName = \"Cleveland\"\n",
    "elif (dataSetIndex == 3):\n",
    "    dataSetFilePath = \"./heartDisease/3_framingham.csv\"\n",
    "    dataSetName = \"framingham\"\n",
    "elif (dataSetIndex == 4):\n",
    "    dataSetFilePath = \"./heartDisease/4_CardiacPrediction.xlsx\"\n",
    "    dataSetName = \"CardiacPrediction\"\n",
    "elif (dataSetIndex == 5):\n",
    "    dataSetFilePath = \"./heartDisease/5_CardiacPredictionLessDimensions.xlsx\"\n",
    "    dataSetName = \"CardiacPrediction\"\n",
    "elif (dataSetIndex == 6):\n",
    "    dataSetFilePath = \"./heartDisease/6_CardiacPredictionFewDimensions.xlsx\"\n",
    "    dataSetName = \"CardiacPrediction\"\n",
    "else:\n",
    "    dataSetFilePath = \"\"\n",
    "    dataSetName = \"\"\n",
    "\n",
    "if(dataSetIndex==4 or dataSetIndex==5 or dataSetIndex==6):\n",
    "    #fileData = pd.read_excel(dataSetFilePath, sheet_name='CoroHeartDis')\n",
    "    fileData = pd.read_excel(dataSetFilePath)\n",
    "else:\n",
    "    fileData = pd.read_csv(dataSetFilePath)\n",
    "\n",
    "print(\"Shape of fileData: {}\".format(fileData.shape))\n",
    "print(\"Column Headings: {}\".format(fileData.__dataframe__().column_names()))\n",
    "print(\"Number of Records: {}\".format(fileData.__dataframe__().num_rows()))\n",
    "\n",
    "\n",
    "missingValues = fileData.isnull().any().sum()\n",
    "print(f\"\\nNumber of Missing Values: {missingValues}\")\n",
    "\n",
    "num_rows_before = fileData.shape[0] \n",
    "fileData.drop_duplicates(inplace=True) \n",
    "num_rows_after = fileData.shape[0] \n",
    "num_duplicates_removed = num_rows_before - num_rows_after\n",
    "print(f\"Number of duplicate records removed: {num_duplicates_removed}\")\n",
    "fileData = fileData.dropna()\n",
    "print(\"Shape of fileData: {}\".format(fileData.shape))   \n",
    "fileData = fileData.fillna(0) \n",
    "\n",
    "print(\"Shape of fileData End: {}\".format(fileData.shape))\n",
    "\n",
    "\n",
    "\n",
    "finalResultTable = [ ['Index', 'Method', 'Accuracy %','Recall %','Precision %','F1 Score','AUC'], ]  \n",
    "\n",
    "X = fileData.drop(fileData.__dataframe__().column_names()[-1], axis=1)  # Features\n",
    "Y = fileData[fileData.__dataframe__().column_names()[-1]]  # Labels\n",
    "\n",
    "columns = fileData.__dataframe__().column_names() \n",
    "totalRecords = (fileData.__dataframe__().num_rows())\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"columns of x:: {} \\n\\n and features of X: {}\".format(len(X.columns), X.columns))\n",
    "\n",
    "dataSetResultDirectory = \"./\"\n",
    "dataSetResultDirectory += (\"DatasetResults_PyTorch_\" + dataSetName)\n",
    "dataSetResultDirectory += \"/\"\n",
    "if not os.path.isdir(dataSetResultDirectory):\n",
    "    os.makedirs(dataSetResultDirectory)\n",
    "\n",
    "dataSetName += \" {}\".format(fileData.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of fileData: (37079, 51) , target Len:37079\n",
      "X: (37079, 50) , Y:(37079,)\n",
      "Before SMOTE Train DataSet Positive Class Records:: 1056\n",
      "Before SMOTE Train DataSet Negative Class Records:: 24899\n",
      "Before SMOTE Train DataSet Total Records:: 25955\n",
      "Target Column Name:: CoronaryHeartDisease \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find the number of physical cores for the following reason:\n",
      "found 0 physical cores < 1\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  File \"c:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 282, in _count_physical_cores\n",
      "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " X Train: Shape:: (49798, 50)\n",
      " X Test: Shape:: (21344, 50)\n",
      "After SMOTE Train DataSet Positive Class Records:: 24899\n",
      "After SMOTE Train DataSet Negative Class Records:: 24899\n",
      "After SMOTE Train DataSet Total Records:: 49798\n",
      "\n",
      "\n",
      "\n",
      "After SMOTE Test DataSet Positive Class Records:: 10672\n",
      "After SMOTE Test DataSet Negative Class Records:: 10672\n",
      "After SMOTE Test DataSet Total Records:: 21344\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of fileData: {} , target Len:{}\".format(fileData.shape, len(Y)))\n",
    "print(\"X: {} , Y:{}\".format(X.shape, Y.shape))\n",
    "#print(\"\\n\\nX: head:: \\n{}\".format(X.head()))\n",
    "#print(\"\\n\\nY: head::\\n {}\".format(Y.head()))\n",
    "\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, stratify=Y, random_state=42)\n",
    "\n",
    "\n",
    "positiveClass =  0\n",
    "negativeClass = 0\n",
    "for i in y_train:\n",
    "    if(i == 0):\n",
    "        negativeClass += 1\n",
    "    if(i == 1):\n",
    "        positiveClass += 1\n",
    "print(\"Before SMOTE Train DataSet Positive Class Records:: {}\".format(positiveClass)) \n",
    "print(\"Before SMOTE Train DataSet Negative Class Records:: {}\".format(negativeClass)) \n",
    "print(\"Before SMOTE Train DataSet Total Records:: {}\".format(positiveClass + negativeClass)) \n",
    "\n",
    "\n",
    "print(\"Target Column Name:: {} \\n\".format(fileData.__dataframe__().column_names()[-1]))\n",
    "\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "'''\n",
    "# Undersample the majority class\n",
    "X_train, y_train = rus.fit_resample(X_train, y_train)\n",
    "X_test, y_test = rus.fit_resample(X_test, y_test)\n",
    "'''\n",
    "\n",
    "\n",
    "print(\"\\n \\n\\n\\n\")\n",
    "\n",
    "# Oversample the minority class using SMOTE\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "#X_test, y_test = rus.fit_resample(X_test, y_test)\n",
    "X_test, y_test = smote.fit_resample(X_test, y_test) \n",
    "\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "#Y_train_scaled = scaler.transform(y_train)\n",
    "#Y_test_scaled = scaler.transform(y_test)\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "print(\"\\n X Train: Shape:: {}\".format(X_train.shape))\n",
    "print(\" X Test: Shape:: {}\".format(X_test.shape))  \n",
    " \n",
    " \n",
    "positiveClass =  0\n",
    "negativeClass = 0\n",
    "for i in y_train:\n",
    "    if(i == 0):\n",
    "        negativeClass += 1\n",
    "    if(i == 1):\n",
    "        positiveClass += 1\n",
    "print(\"After SMOTE Train DataSet Positive Class Records:: {}\".format(positiveClass)) \n",
    "print(\"After SMOTE Train DataSet Negative Class Records:: {}\".format(negativeClass)) \n",
    "print(\"After SMOTE Train DataSet Total Records:: {}\".format(positiveClass + negativeClass)) \n",
    "\n",
    "print(\"\\n\\n\") \n",
    "\n",
    "\n",
    "positiveClass =  0\n",
    "negativeClass = 0\n",
    "for i in y_test:\n",
    "    if(i == 0):\n",
    "        negativeClass += 1\n",
    "    if(i == 1):\n",
    "        positiveClass += 1\n",
    "print(\"After SMOTE Test DataSet Positive Class Records:: {}\".format(positiveClass)) \n",
    "print(\"After SMOTE Test DataSet Negative Class Records:: {}\".format(negativeClass)) \n",
    "print(\"After SMOTE Test DataSet Total Records:: {}\".format(positiveClass + negativeClass)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCorrelationPic(correlationMatrix, numberOfTopFeatures, targetColumnName):     \n",
    "    correlation_values = correlationMatrix.abs()\n",
    "    sorted_correlation = correlation_values.unstack().sort_values(ascending=False)\n",
    "    sorted_correlation = sorted_correlation[sorted_correlation != 1.0]\n",
    "\n",
    "    num_features = numberOfTopFeatures  # Number of top features to display\n",
    "    top_features = sorted_correlation.head(num_features)\n",
    "    print(\"Top\", num_features, \"features based on correlation:\")\n",
    "    print(top_features)\n",
    " \n",
    "    top_features = correlationMatrix.abs().nlargest(numberOfTopFeatures, targetColumnName)[targetColumnName].index\n",
    "    top_correlation_matrix = correlationMatrix.loc[top_features, top_features]\n",
    "\n",
    "    mplot.figure(figsize=(10, 8))\n",
    "    sns.heatmap(top_correlation_matrix, annot=True, cmap='coolwarm')\n",
    "    # Set the title of the plot\n",
    "    mplot.title('Correlation Heatmap ({})'.format(dataSetName))\n",
    "    \n",
    "    picturePath = \"Correlation_Matrix_DateSetName_{}.png\".format(dataSetName)\n",
    "    mplot.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "    mplot.show()\n",
    "    mplot.close()\n",
    "\n",
    "def makeConfusionMatrixPic(method, dataSet, classifierObj , X_test, y_test, predicted_Y):\n",
    "    display = ConfusionMatrixDisplay.from_estimator(classifierObj, X_test, y_test, display_labels=['Healthy', \"Heart Disease\"], cmap=mplot.cm.Blues) #, normalize=\"true\"\n",
    "    display.ax_.set_title(\"Confusion Matrix ({} Model)\".format(method))\n",
    "    display.ax_.set_xlabel('\\nPredicted Values')\n",
    "    display.ax_.set_ylabel('Actual Values ')\n",
    "\n",
    "\n",
    "    accuracyString =\"Accuracy {}: {:.2f}\".format(method, accuracy_score(y_test, predicted_Y)*100.0 ) \n",
    "    recallString =  'Recall {}: {:.2f}'.format(method, recall_score(y_test, predicted_Y) * 100.0)\n",
    "    precisionString = 'Precision {}: {:.2f}'.format(method, precision_score(y_test, predicted_Y) * 100.0) \n",
    "    dataSetString = \"Dataset: {}\".format(dataSet)\n",
    "\n",
    "    \n",
    "    if(classifierObj.n_features_in_ > 10):\n",
    "        featureListString = 'Total Features: {}'.format(classifierObj.n_features_in_) \n",
    "    else:\n",
    "        featureListString = 'Features: {}'.format(classifierObj.feature_names_in_) \n",
    "    \n",
    "    display.figure_.text(0.010, -0.05,  accuracyString, horizontalalignment='left', wrap=False )  \n",
    "    display.figure_.text(0.010, -0.09,  recallString, horizontalalignment='left', wrap=False )      \n",
    "    display.figure_.text(0.010, -0.13,  precisionString, horizontalalignment='left', wrap=False ) \n",
    "    display.figure_.text(0.010, -0.17,  dataSetString, horizontalalignment='left', wrap=False ) \n",
    "    display.figure_.text(0.010, -0.28,  featureListString, horizontalalignment='left', wrap=False ) \n",
    " \n",
    "    picturePath = \"{}Confusion_Matrix_{}_{}.png\".format(dataSetResultDirectory, method, dataSetName)\n",
    "    mplot.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "    #print(\"{} Confusion Matrix saved:: path: {}\".format(method, picturePath))\n",
    "    #os.startfile(picturePath)\n",
    "    mplot.show()\n",
    "    mplot.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.CustomDataset object at 0x0000022683212C80>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x0000022683213E80>\n"
     ]
    }
   ],
   "source": [
    "# Convert to PyTorch tensors\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    " \n",
    "X_train_tensor = torch.tensor(X_train.to_numpy(), dtype=torch.float32).cuda()\n",
    "y_train_tensor = torch.tensor(y_train.to_numpy(), dtype=torch.float32).cuda()\n",
    "X_test_tensor = torch.tensor(X_test.to_numpy(), dtype=torch.float32).cuda()\n",
    "y_test_tensor = torch.tensor(y_test.to_numpy(), dtype=torch.float32).cuda()\n",
    "#print(X_train_tensor)\n",
    "#print(y_train_tensor) \n",
    "# Define a custom dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "    \n",
    "train_dataset = CustomDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = CustomDataset(X_test_tensor, y_test_tensor)\n",
    "print(train_dataset)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "print(train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (49798, 50)   and dType: 50\n",
      "y_train shape: (49798,)   and dType: int64\n",
      "X_train_tensor shape: torch.Size([49798, 50])   and dType: torch.float32\n",
      "y_train_tensor shape: torch.Size([49798])   and dType: torch.float32\n",
      "X_test_tensor shape: torch.Size([21344, 50])   and dType: torch.float32\n",
      "y_test_tensor shape: torch.Size([21344])   and dType: torch.float32\n",
      "features shape: torch.Size([49798, 50])   and dType: torch.float32\n",
      "target shape: torch.Size([49798])   and dType: torch.float32\n"
     ]
    }
   ],
   "source": [
    "features = X_train_tensor \n",
    "target = y_train_tensor\n",
    " \n",
    "  \n",
    "print(\"X_train shape: {}   and dType: {}\".format(X_train.shape, len(X_train.columns)))\n",
    "print(\"y_train shape: {}   and dType: {}\".format(y_train.shape, y_train.dtype))  \n",
    "\n",
    "print(\"X_train_tensor shape: {}   and dType: {}\".format(X_train_tensor.shape, X_train_tensor.dtype))\n",
    "print(\"y_train_tensor shape: {}   and dType: {}\".format(y_train_tensor.shape, y_train_tensor.dtype)) \n",
    "\n",
    "print(\"X_test_tensor shape: {}   and dType: {}\".format(X_test_tensor.shape, X_test_tensor.dtype))\n",
    "print(\"y_test_tensor shape: {}   and dType: {}\".format(y_test_tensor.shape, y_test_tensor.dtype)) \n",
    "\n",
    "print(\"features shape: {}   and dType: {}\".format(features.shape, features.dtype))\n",
    "print(\"target shape: {}   and dType: {}\".format(target.shape, target.dtype)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    " \n",
    "\n",
    "# Define the attention layer\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=input_size, num_heads=1)\n",
    "    def forward_2(self, q, v):\n",
    "        attention_weights, _ = self.attention(q.unsqueeze(0), v.unsqueeze(0), v.unsqueeze(0))\n",
    "        return attention_weights.squeeze(0)\n",
    "    \n",
    "    def forward(self, q, v):\n",
    "        attention = self.attention(q, v, v)\n",
    "        return attention\n",
    "\n",
    "# Define the model\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, input_size): \n",
    "        super(CustomModel, self).__init__()\n",
    "         # Traditional neural network part\n",
    "        self.fc1 = nn.Linear(input_size, input_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(input_size, input_size)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(input_size, input_size)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.batch_norm = nn.BatchNorm1d(input_size)\n",
    "        # Attention layer\n",
    "        self.attention = AttentionLayer(input_size)\n",
    "        # Output layer\n",
    "        self.fc4 = nn.Linear(input_size*2, input_size)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.batch_norm2 = nn.BatchNorm1d(input_size)\n",
    "        self.fc5 = nn.Linear(input_size, input_size//2)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.fc6 = nn.Linear(input_size//2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x): \n",
    "     # Traditional neural network part\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.batch_norm(x)\n",
    "        # Detach the gradient for interpretability\n",
    "        x_detached = x.detach()\n",
    "        # Attention layer\n",
    "        attention = self.attention(x_detached, x_detached) \n",
    "        # Combine the output of the attention layer with the previous layer\n",
    "        x = torch.cat([x, attention], dim=1)\n",
    "        # Output layer\n",
    "        x = self.fc4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.fc5(x)\n",
    "        x = self.relu5(x)\n",
    "        x = self.fc6(x)\n",
    "        output = self.sigmoid(x)\n",
    "\n",
    "        return output\n",
    "     \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def predict_proba(self, x): \n",
    "        logits = self.forward(x)\n",
    "        probs = torch.sigmoid(logits) # .detach().cpu().numpy()\n",
    "        return probs\n",
    "    \n",
    "\n",
    "# Instantiate the model\n",
    "input_size = X_train_tensor.shape[1]  # Assuming 'features' is a torch tensor\n",
    "print(input_size)\n",
    "model = CustomModel(input_size).cuda()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |  14278 KiB |  14278 KiB |  14278 KiB |      0 B   |\n",
      "|       from large pool |  13895 KiB |  13895 KiB |  13895 KiB |      0 B   |\n",
      "|       from small pool |    383 KiB |    383 KiB |    383 KiB |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |  14278 KiB |  14278 KiB |  14278 KiB |      0 B   |\n",
      "|       from large pool |  13895 KiB |  13895 KiB |  13895 KiB |      0 B   |\n",
      "|       from small pool |    383 KiB |    383 KiB |    383 KiB |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |  14268 KiB |  14268 KiB |  14268 KiB |      0 B   |\n",
      "|       from large pool |  13894 KiB |  13894 KiB |  13894 KiB |      0 B   |\n",
      "|       from small pool |    374 KiB |    374 KiB |    374 KiB |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |  22528 KiB |  22528 KiB |  22528 KiB |      0 B   |\n",
      "|       from large pool |  20480 KiB |  20480 KiB |  20480 KiB |      0 B   |\n",
      "|       from small pool |   2048 KiB |   2048 KiB |   2048 KiB |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |   8249 KiB |  12606 KiB |  12606 KiB |   4357 KiB |\n",
      "|       from large pool |   6584 KiB |  10753 KiB |  10753 KiB |   4169 KiB |\n",
      "|       from small pool |   1665 KiB |   1853 KiB |   1853 KiB |    188 KiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |      30    |      30    |      30    |       0    |\n",
      "|       from large pool |       2    |       2    |       2    |       0    |\n",
      "|       from small pool |      28    |      28    |      28    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |      30    |      30    |      30    |       0    |\n",
      "|       from large pool |       2    |       2    |       2    |       0    |\n",
      "|       from small pool |      28    |      28    |      28    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       2    |       2    |       2    |       0    |\n",
      "|       from large pool |       1    |       1    |       1    |       0    |\n",
      "|       from small pool |       1    |       1    |       1    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       2    |       2    |       2    |       0    |\n",
      "|       from large pool |       1    |       1    |       1    |       0    |\n",
      "|       from small pool |       1    |       1    |       1    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 9.24 GiB. GPU 0 has a total capacty of 4.00 GiB of which 0 bytes is free. Of the allocated memory 9.33 GiB is allocated by PyTorch, and 23.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(numberOfEpochs): \n\u001b[1;32m---> 10\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(output, y_train_tensor) \n\u001b[0;32m     12\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()    \n",
      "File \u001b[1;32mc:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[7], line 57\u001b[0m, in \u001b[0;36mCustomModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     55\u001b[0m x_detached \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Attention layer\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m attention \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_detached\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_detached\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Combine the output of the attention layer with the previous layer\u001b[39;00m\n\u001b[0;32m     59\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x, attention], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[7], line 19\u001b[0m, in \u001b[0;36mAttentionLayer.forward\u001b[1;34m(self, q, v)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, q, v):\n\u001b[1;32m---> 19\u001b[0m     attention \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attention\n",
      "File \u001b[1;32mc:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\activation.py:1241\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   1227\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[0;32m   1228\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[0;32m   1229\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1238\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[0;32m   1239\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[0;32m   1240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1241\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1245\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[0;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[1;32mc:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:5406\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   5404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5405\u001b[0m     attn_output_weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbmm(q_scaled, k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m-> 5406\u001b[0m attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_output_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dropout_p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m   5408\u001b[0m     attn_output_weights \u001b[38;5;241m=\u001b[39m dropout(attn_output_weights, p\u001b[38;5;241m=\u001b[39mdropout_p)\n",
      "File \u001b[1;32mc:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:1856\u001b[0m, in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1854\u001b[0m     dim \u001b[38;5;241m=\u001b[39m _get_softmax_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim(), _stacklevel)\n\u001b[0;32m   1855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1856\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1858\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 9.24 GiB. GPU 0 has a total capacty of 4.00 GiB of which 0 bytes is free. Of the allocated memory 9.33 GiB is allocated by PyTorch, and 23.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "numberOfEpochs = 30\n",
    "batchSizeOfTraining = 2 \n",
    "accumulation_steps = 4\n",
    "import gc\n",
    "\n",
    "y_train_tensor = y_train_tensor.view(-1, 1) \n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "for epoch in range(numberOfEpochs): \n",
    "    output = model(X_train_tensor)\n",
    "    loss = criterion(output, y_train_tensor) \n",
    "    loss.backward()    \n",
    "    # Accumulate gradients for a specified number of steps\n",
    "    if (i + 1) % accumulation_steps  == 0:\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        del output, loss\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "         \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test_tensor).cuda() #.numpy()\n",
    "\n",
    "# Convert the list to a PyTorch tensor\n",
    "binary_predictions_tensor = torch.tensor([1 if pred > 0.5 else 0 for pred in y_pred])\n",
    "binary_predictions_tensor = binary_predictions_tensor.cuda()\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_test_cpu = y_test_tensor.cpu().view(-1, 1).numpy()\n",
    "binary_predictions_cpu = binary_predictions_tensor.cpu().numpy()\n",
    "\n",
    "loss = criterion(torch.tensor(y_pred), y_test_tensor.view(-1, 1).cuda()).item()\n",
    "accuracy = accuracy_score(y_test_cpu, binary_predictions_cpu)\n",
    "recall_value = recall_score(y_test_cpu, binary_predictions_cpu)\n",
    "precision_value = precision_score(y_test_cpu, binary_predictions_cpu)\n",
    "f1_score_value = f1_score(y_test_cpu, binary_predictions_cpu)\n",
    "auc_value = roc_auc_score(y_test_cpu, binary_predictions_cpu)\n",
    "\n",
    "# Print the results\n",
    "print('Test loss: {}'.format(loss*100))\n",
    "print('Test accuracy: {}'.format(accuracy*100))\n",
    "print('Test recall: {}'.format(recall_value*100))\n",
    "print('Test precision: {}'.format(precision_value*100))\n",
    "print('Test F1 score: {}'.format(f1_score_value*100))\n",
    "print('Test AUC: {}'.format(auc_value*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = ConfusionMatrixDisplay.from_predictions(y_test_cpu, binary_predictions_cpu, display_labels=['Healthy', 'Heart Disease'], cmap=mplot.cm.Blues)\n",
    "\n",
    "#display = ConfusionMatrixDisplay.from_estimator(model, X_test_scaler, y_test, display_labels=['Healthy', \"Heart Disease\"], cmap=mplot.cm.Blues) #, normalize=\"true\"\n",
    "method = \"MLP with Attention layers\"\n",
    "display.ax_.set_title(\"Results {} Model\".format(method))\n",
    "display.ax_.set_xlabel('\\nPredicted Values')\n",
    "display.ax_.set_ylabel('Actual Values ')\n",
    "\n",
    "accuracyString =\"Accuracy {}: {:.2f}\".format(method, (accuracy*100.0) ) \n",
    "recallString =  'Recall {}: {:.2f}'.format(method, (recall_value*100.0))\n",
    "precisionString = 'Precision {}: {:.2f}'.format(method, (precision_value*100.0)) \n",
    "dataSetString = \"F1 Score: {}\".format((f1_score_value*100.0))\n",
    "featureListString = \"AUC Score: {}\".format(auc_value*100.0)\n",
    "numberOfEpochsString = \"Number of Epoches: {}\".format(numberOfEpochs)\n",
    "batchSizeOfTrainingString = \"BatchSize for Epoch: {}\".format(batchSizeOfTraining)\n",
    "\n",
    "display.figure_.text(0.010, -0.05,  accuracyString, horizontalalignment='left', wrap=False )  \n",
    "display.figure_.text(0.010, -0.09,  recallString, horizontalalignment='left', wrap=False )      \n",
    "display.figure_.text(0.010, -0.13,  precisionString, horizontalalignment='left', wrap=False ) \n",
    "display.figure_.text(0.010, -0.17,  dataSetString, horizontalalignment='left', wrap=False ) \n",
    "display.figure_.text(0.010, -0.21,  featureListString, horizontalalignment='left', wrap=False ) \n",
    "display.figure_.text(0.010, -0.28,  numberOfEpochsString, horizontalalignment='left', wrap=False ) \n",
    "display.figure_.text(0.010, -0.32,  batchSizeOfTrainingString, horizontalalignment='left', wrap=False ) \n",
    " \n",
    "picturePath = \"{}Model_Evaluation_{}_{}_Epoch_{}.png\".format(dataSetResultDirectory, method, dataSetName, numberOfEpochs)\n",
    "mplot.savefig(picturePath,  dpi=300, bbox_inches='tight') \n",
    "\n",
    "mplot.show()\n",
    "mplot.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage = 0.10\n",
    "numberOfFeatures = int(len(features) *percentage) \n",
    "featuresForShap = X_train.columns  \n",
    "print(\"Total Features: {} -> Selected for SHAP:: {}\".format(len(features), numberOfFeatures))\n",
    "numberOftest = int(len(X_test_tensor) * percentage) \n",
    "testForShap = X_test_tensor[0:numberOftest] \n",
    "print(\" testForShap length: {}\".format( len(testForShap)))\n",
    " \n",
    "# Create SHAP explainer\n",
    "shap_explainer = shap.DeepExplainer(model, testForShap)\n",
    "shap_values = shap_explainer.shap_values(testForShap)\n",
    "shap.summary_plot(shap_values, features=testForShap, feature_names=featuresForShap, show=False)\n",
    "\n",
    "ax = mplot.gca() \n",
    "#ax.set_title(\"XAI SHAP Explainer ({} Model)\".format(method) ,fontsize=16, fontweight='bold')     \n",
    "ax.set_title(\"XAI SHAP Explainer \" ,fontsize=16, fontweight='bold')     \n",
    "\n",
    "dataSetString = \"Dataset:  {}\".format(dataSetName)\n",
    "testingDatasetString =\"length of Testing Set: {}\".format(len(testForShap))\n",
    "shapTypeString =\"SHAP Type: {}\".format(repr(shap_explainer)) \n",
    "ax.figure.text(0.020, -0.05,  dataSetString, horizontalalignment='left', wrap=False )  \n",
    "ax.figure.text(0.020, -0.09,  testingDatasetString, horizontalalignment='left', wrap=False )   \n",
    "ax.figure.text(0.020, -0.13,  shapTypeString, horizontalalignment='left', wrap=False )   \n",
    "\n",
    "picturePath = \"{}XAI_SHAP_Explainer2_{}_{}_numberOfSamples_{}.png\".format(dataSetResultDirectory, method, dataSetName, len(testForShap))\n",
    "mplot.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "mplot.show()\n",
    "mplot.close() \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dalex as dx \n",
    "#torch.cuda.empty_cache()\n",
    "\n",
    "X_data = X_train_tensor[0:10]\n",
    "Y_data = y_train_tensor[0:10]\n",
    "\n",
    " \n",
    "\n",
    "# Convert PyTorch tensors back to pandas DataFrame\n",
    "X_train_df = pd.DataFrame(X_data.cpu().numpy(), columns=X_train.columns)\n",
    "y_train_df = pd.DataFrame(Y_data.cpu().numpy(), columns=[y_train.name])\n",
    "\n",
    "# Convert PyTorch model to a Dalex Explainer\n",
    "explainer = dx.Explainer(model, X_train_df, y_train_df, label=\"CustomModel\", verbose=True)\n",
    "\n",
    "# Create a DALEX model wrapper for the PyTorch model\n",
    "model_dalex = dx.ModelWrapper(model, predict_function=model.predict_proba)\n",
    "\n",
    "# Plot the variable importance\n",
    "variable_importance_plot = explainer.model_parts()\n",
    "variable_importance_plot.plot()\n",
    " \n",
    "# Convert PyTorch model to a Dalex Explainer\n",
    "explainer = dx.Explainer(model, X_data, Y_data, label=\"CustomModel\", verbose=True, predict_function=model.predict_proba)\n",
    "\n",
    "# Create a DALEX model wrapper for the PyTorch model\n",
    "#model_dalex = dx.ModelWrapper(model, predict_function=model.predict_proba)\n",
    "\n",
    "# Plot the variable importance\n",
    "variable_importance_plot = explainer.model_parts()\n",
    "variable_importance_plot.plot()\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "from lime import lime_tabular\n",
    " \n",
    "X_data = X_train_tensor[0:10]\n",
    "Y_data = y_train_tensor[0:10] \n",
    "X_train_df = pd.DataFrame(X_data.cpu().detach().numpy(), columns=X_train.columns)\n",
    "y_train_df = pd.DataFrame(Y_data.cpu().detach().numpy(), columns=[y_train.name])\n",
    "\n",
    "# Create a function that uses the PyTorch model for predictions\n",
    "def pytorch_predict_fn(data):\n",
    "    data_tensor = torch.tensor(data, dtype=torch.float32).cuda()\n",
    "    return model.predict_proba(data_tensor).cpu().detach().numpy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "# Create a LimeTabularExplainer\n",
    "explainer = lime_tabular.LimeTabularExplainer(X_train_df.values,  feature_names=X_train.columns.tolist(),\n",
    "                                              class_names=['CoronaryHeartDisease'],  # Adjust class names accordingly\n",
    "                                              discretize_continuous=True, mode='classification')\n",
    "\n",
    "# Choose an instance for which you want an explanation\n",
    "instance_idx = 0\n",
    "instance = X_test_tensor[instance_idx].cpu().detach().numpy()\n",
    "instance = instance.flatten()  # or instance.squeeze()\n",
    "print(instance)\n",
    "print(len(instance))\n",
    "# Get an explanation for the instance\n",
    "explanation = explainer.explain_instance(instance, pytorch_predict_fn, num_features=len(X_train.columns))\n",
    "\n",
    "# Plot the explanation\n",
    "explanation.show_in_notebook(show_table=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pdpbox  \n",
    "from pdpbox import pdp \n",
    "\n",
    "from pdpbox import info_plots\n",
    "#fig, axes, summary_df = info_plots.TargetPlot( df=fileData, feature=fileData[['Gender']], feature_name='Gender', target=Y)\n",
    "#fig, axes, summary_df = info_plots.TargetPlot( df=fileData, feature=fileData['Gender'], feature_name='Gender', target=Y)\n",
    "X_data = X_train[0:10]\n",
    "\n",
    "feature = 'sex'\n",
    "feature_name = 'Gender' \n",
    "\n",
    " \n",
    "# Example for generating PDP for a specific feature (replace 'feature_name' with the actual feature name)\n",
    "#pdp_feature = pdp.pdp_isolate(model=model, dataset=X_data, model_features=X_data.columns, feature_names=['feature_name'])\n",
    "pdp_feature = pdp.pdp_plot (model=model, dataset=X_data)\n",
    "\n",
    "# Plot the PDP\n",
    "pdpbox.pdp.pdp_plot(pdp_feature, feature_name)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.show()\n",
    " \n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdpbox import info_plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'Gender' is a column in your DataFrame\n",
    "feature_name = 'Gender'\n",
    "\n",
    "fig, axes, summary_df = info_plots.TargetPlot(df=fileData, feature=fileData['Gender'], feature_name='Gender', target=Y)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dalex as dx\n",
    "dx.__version__\n",
    "numberOftest = int((len(y_test_tensor) * percentage))\n",
    "y_trainForXAI = y_test_tensor[0:numberOftest]  \n",
    "#print(numberOftest)\n",
    "#print(y_trainForXAI)\n",
    "\n",
    "def predict_function(model, data): \n",
    "    #print(\"\\n\\n data :: {}\".format(data)) \n",
    "    data_tensor = torch.from_numpy(data)     \n",
    "    #print(\"\\n\\n data_tensor :: {}\".format(data_tensor)) \n",
    "    predValue = model.predict_proba(data_tensor)\n",
    "    print(\"\\n\\npredict_function :: {}\".format(predValue)) \n",
    "    predValue = predValue.detach().cpu().numpy()\n",
    "    print(\"\\n\\npredict_function :: {}\".format(predValue[:, 1]))   \n",
    "    return predValue[:, 1]\n",
    "  \n",
    "\n",
    "# Convert testForShap and y_trainForXAI to NumPy arrays\n",
    "test_for_shap_numpy = testForShap.detach().cpu().numpy()\n",
    "y_train_for_xai_numpy = y_trainForXAI.detach().cpu().numpy()\n",
    " \n",
    "\n",
    "explainer = dx.Explainer(model, test_for_shap_numpy, y_train_for_xai_numpy,  predict_function=predict_function, label='CoronaryHeartDisease', model_type='regression')\n",
    "\n",
    "\n",
    "print(\"Working \")\n",
    "\n",
    "\n",
    "explainer.model_performance()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "explainer.model_parts().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapash.explainer.consistency import Consistency\n",
    "cns = Consistency()\n",
    "\n",
    "cns.compile(model , x=X_test_tensor  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert your training data to NumPy\n",
    "X_train_numpy = testForShap.cuda().numpy()\n",
    "\n",
    "# Define a predict function for your PyTorch model\n",
    "def predict_function(data):\n",
    "    input_tensor = torch.tensor(data, dtype=torch.float32)\n",
    "    output = model(input_tensor)\n",
    "    return output.detach().numpy()\n",
    "\n",
    "# Create a LIME explainer\n",
    "explainer = lime_tabular.LimeTabularExplainer(X_train_numpy, feature_names=featuresForShap, mode='regression')\n",
    "# Get LIME explanations for a single instance\n",
    "explanation = explainer.explain_instance(X_train_numpy[0], predict_function, num_features=len(featuresForShap))\n",
    "# Visualize the LIME explanation\n",
    "lime_summary_plot = explanation.as_pyplot_figure()\n",
    "\n",
    "# Save Lime explanation summary plot as a PNG file\n",
    "lime_picture_path = \"{}XAI_LIME_Explainer_{}_{}_numberOfSamples_{}.png\".format(dataSetResultDirectory, method, dataSetName, len(X_train_numpy))\n",
    "lime_summary_plot.savefig(lime_picture_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()  # Close the figure to release resources and avoid displaying the plot\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "from lime import lime_tabular\n",
    " \n",
    "# Define a function that takes numpy arrays as input and returns model predictions\n",
    "def predict_function(data):\n",
    "     return np.zeros(data.shape[0]) \n",
    "\n",
    "\n",
    "# Convert your training data to NumPy\n",
    "X_train_numpy = X_train_tensor.cpu().detach().numpy()\n",
    "\n",
    "# Create a LIME explainer\n",
    "explainer = lime_tabular.LimeTabularExplainer(X_train_numpy,  feature_names=featuresForShap,  mode='regression')\n",
    "\n",
    "# Get LIME explanations for a single instance\n",
    "explanation = explainer.explain_instance(testForShap[0], predict_function,  num_features=len(featuresForShap))\n",
    "\n",
    "# Visualize the LIME explanation\n",
    "lime_summary_plot = explanation.as_pyplot_figure()\n",
    "\n",
    "lime_summary_plot.set_title(\"XAI SHAP Explainer ({} Model)\".format(method) ,fontsize=16, fontweight='bold')     \n",
    "\n",
    "dataSetString = \"Dataset:  {}\".format(dataSetName)\n",
    "testingDatasetString =\"length of Testing Set: {}\".format(len(testForShap))\n",
    "shapTypeString =\"SHAP Type: {}\".format(repr(shap_explainer)) \n",
    "lime_summary_plot.figure.text(0.020, -0.05,  dataSetString, horizontalalignment='left', wrap=False )  \n",
    "lime_summary_plot.figure.text(0.020, -0.09,  testingDatasetString, horizontalalignment='left', wrap=False )   \n",
    "lime_summary_plot.figure.text(0.020, -0.13,  shapTypeString, horizontalalignment='left', wrap=False )   \n",
    "\n",
    "# Save Lime explanation summary plot as a PNG file\n",
    "lime_picture_path = \"{}XAI_LIME_Explainer_{}_{}_numberOfSamples_{}.png\".format(dataSetResultDirectory, method, dataSetName, len(testForShap))\n",
    "lime_summary_plot.savefig(lime_picture_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()  # Close the figure to release resources and avoid displaying the plot\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage = 0.07\n",
    "numberOfFeatures = int(len(features) *percentage)\n",
    "print(\"Total Features: {} -> Selected for SHAP:: {}\".format(len(features), numberOfFeatures))\n",
    "featuresForShap = X_train.columns #features[0:numberOfFeatures]\n",
    "#print(\" Features Name: {}\".format(  featuresForShap))\n",
    "\n",
    "numberOftest = int(len(X_test_tensor) * percentage)\n",
    "print(\"Total Test: {} -> Selected for SHAP:: {}\".format(len(X_test_tensor), numberOftest))\n",
    "#testForShap = X_test_tensor[0:len(featuresForShap)]\n",
    "testForShap = X_test_tensor[0:numberOftest]\n",
    "#print(\" testForShap Name: {}\".format(  testForShap))\n",
    "testForShap_numpy = testForShap.cpu().detach().numpy()\n",
    "\n",
    "# Convert the NumPy array back to a PyTorch tensor for SHAP values computation\n",
    "testForShap_tensor2 = torch.from_numpy(testForShap_numpy)\n",
    "\n",
    "\n",
    " \n",
    "def makeSHAPreport(method, model):\n",
    "    shap_explainer = shap.Explainer(model, feature_names=featuresForShap, masker=shap.maskers.Independent(data=testForShap_numpy)) \n",
    "    shap_values = shap_explainer.shap_values(testForShap)  \n",
    "    shap.summary_plot(shap_values, testForShap_numpy, featuresForShap, show=False)\n",
    "    ax = mplot.gca() \n",
    "    ax.set_title(\"XAI SHAP Explainer ({} Model)\".format(method) ,fontsize=16, fontweight='bold')     \n",
    "\n",
    "    dataSetString = \"Dataset:  {}\".format(dataSetName)\n",
    "    testingDatasetString =\"length of Testing Set: {}\".format(len(testForShap_numpy))\n",
    "    shapTypeString =\"SHAP Type: {}\".format(repr(shap_explainer)) \n",
    "    ax.figure.text(0.020, -0.05,  dataSetString, horizontalalignment='left', wrap=False )  \n",
    "    ax.figure.text(0.020, -0.09,  testingDatasetString, horizontalalignment='left', wrap=False )   \n",
    "    ax.figure.text(0.020, -0.13,  shapTypeString, horizontalalignment='left', wrap=False )   \n",
    "\n",
    "    picturePath = \"{}XAI_SHAP_Explainer_{}_{}_numberOfSamples_{}.png\".format(dataSetResultDirectory, method, dataSetName, len(testForShap_numpy))\n",
    "    mplot.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "    #mplot.savefig(picturePath,  dpi=300) \n",
    "    mplot.show()\n",
    "    #os.startfile(picturePath)\n",
    "    mplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    " \n",
    "y_test_cpu = y_test_tensor.cpu().numpy()\n",
    "\n",
    "# Convert to binary predictions (assuming binary classification)\n",
    "binary_predictions = [1 if pred > 0.5 else 0 for pred in y_pred]\n",
    "\n",
    "# Draw confusion matrix\n",
    "cm = confusion_matrix(y_test_cpu, binary_predictions)\n",
    "mplot.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "mplot.xlabel(\"Predicted\")\n",
    "mplot.ylabel(\"True\")\n",
    "picturePath = \"{}Confusion_Matrix_{}_{}.png\".format(dataSetResultDirectory, \"MLP+Attention\", dataSetName)\n",
    "mplot.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "mplot.show()\n",
    "mplot.close()\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test_cpu, binary_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':16:8'\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        predictions.extend(outputs.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Convert to binary predictions (assuming binary classification)\n",
    "binary_predictions = [1 if pred > 0.5 else 0 for pred in predictions]\n",
    "\n",
    "# Draw confusion matrix\n",
    "cm = confusion_matrix(true_labels, binary_predictions)\n",
    "mplot.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "mplot.xlabel(\"Predicted\")\n",
    "mplot.ylabel(\"True\")\n",
    "mplot.show()\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(true_labels, binary_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
