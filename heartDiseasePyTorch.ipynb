{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split \n",
    "from torch.nn import functional as F  \n",
    "import torch.optim as optim\n",
    "from torchsummary import summary \n",
    "\n",
    " \n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as mplot\n",
    "from matplotlib.colors import ListedColormap\n",
    "import os\n",
    "import subprocess\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score, f1_score, precision_score, recall_score,  precision_recall_fscore_support\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    " \n",
    " # Convert to PyTorch tensors\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary \n",
    "\n",
    "\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import pydotplus\n",
    "import seaborn as sns\n",
    "\n",
    "from tabulate import tabulate \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSetIndex = 4\n",
    "needToMakePictureOfTrees = 0\n",
    "''' ---------------------------------------------------------- '''\n",
    "dataSetFilePath = \"\"\n",
    "dataSetName = \"\"\n",
    "dataSetResultDirectory = \"./\"\n",
    "\n",
    "if(dataSetIndex == 0):\n",
    "    dataSetFilePath = \"./heartDisease/0_statLog_dataSet.csv\"\n",
    "    dataSetName = \"SateLog_DataSet\"\n",
    "elif (dataSetIndex == 1):\n",
    "    dataSetFilePath = \"./heartDisease/1_heart_statlog_cleveland_hungary_final.csv\"\n",
    "    dataSetName = \"ALL_StateLog_CleveLand_Hungary\"\n",
    "elif (dataSetIndex == 2):\n",
    "    dataSetFilePath = \"./heartDisease/2_cleveland.csv\"\n",
    "    dataSetName = \"Cleveland\"\n",
    "elif (dataSetIndex == 3):\n",
    "    dataSetFilePath = \"./heartDisease/3_framingham.csv\"\n",
    "    dataSetName = \"framingham\"\n",
    "elif (dataSetIndex == 4):\n",
    "    dataSetFilePath = \"./heartDisease/4_CardiacPrediction.xlsx\"\n",
    "    dataSetName = \"CardiacPrediction\"\n",
    "elif (dataSetIndex == 5):\n",
    "    dataSetFilePath = \"./heartDisease/5_CardiacPredictionLessDimensions.xlsx\"\n",
    "    dataSetName = \"CardiacPrediction\"\n",
    "elif (dataSetIndex == 6):\n",
    "    dataSetFilePath = \"./heartDisease/6_CardiacPredictionFewDimensions.xlsx\"\n",
    "    dataSetName = \"CardiacPrediction\"\n",
    "else:\n",
    "    dataSetFilePath = \"\"\n",
    "    dataSetName = \"\"\n",
    "\n",
    "if(dataSetIndex==4 or dataSetIndex==5 or dataSetIndex==6):\n",
    "    #fileData = pd.read_excel(dataSetFilePath, sheet_name='CoroHeartDis')\n",
    "    fileData = pd.read_excel(dataSetFilePath)\n",
    "else:\n",
    "    fileData = pd.read_csv(dataSetFilePath)\n",
    "\n",
    "print(\"Shape of fileData: {}\".format(fileData.shape))\n",
    "print(\"Column Headings: {}\".format(fileData.__dataframe__().column_names()))\n",
    "print(\"Number of Records: {}\".format(fileData.__dataframe__().num_rows()))\n",
    "\n",
    "\n",
    "missingValues = fileData.isnull().any().sum()\n",
    "print(f\"\\nNumber of Missing Values: {missingValues}\")\n",
    "\n",
    "num_rows_before = fileData.shape[0] \n",
    "fileData.drop_duplicates(inplace=True) \n",
    "num_rows_after = fileData.shape[0] \n",
    "num_duplicates_removed = num_rows_before - num_rows_after\n",
    "print(f\"Number of duplicate records removed: {num_duplicates_removed}\")\n",
    "fileData = fileData.dropna()\n",
    "print(\"Shape of fileData: {}\".format(fileData.shape))   \n",
    "fileData = fileData.fillna(0) \n",
    "\n",
    "print(\"Shape of fileData End: {}\".format(fileData.shape))\n",
    "\n",
    "\n",
    "\n",
    "finalResultTable = [ ['Index', 'Method', 'Accuracy %','Recall %','Precision %','F1 Score','AUC'], ]  \n",
    "\n",
    "X = fileData.drop(fileData.__dataframe__().column_names()[-1], axis=1)  # Features\n",
    "Y = fileData[fileData.__dataframe__().column_names()[-1]]  # Labels\n",
    "\n",
    "columns = fileData.__dataframe__().column_names() \n",
    "totalRecords = (fileData.__dataframe__().num_rows())\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"columns of x:: {} \\n\\n and features of X: {}\".format(len(X.columns), X.columns))\n",
    "\n",
    "dataSetResultDirectory = \"./\"\n",
    "dataSetResultDirectory += (\"DatasetResults_PyTorch_\" + dataSetName)\n",
    "dataSetResultDirectory += \"/\"\n",
    "if not os.path.isdir(dataSetResultDirectory):\n",
    "    os.makedirs(dataSetResultDirectory)\n",
    "\n",
    "dataSetName += \" {}\".format(fileData.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of fileData: {} , target Len:{}\".format(fileData.shape, len(Y)))\n",
    "print(\"X: {} , Y:{}\".format(X.shape, Y.shape))\n",
    "#print(\"\\n\\nX: head:: \\n{}\".format(X.head()))\n",
    "#print(\"\\n\\nY: head::\\n {}\".format(Y.head()))\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, stratify=Y, random_state=42)\n",
    " \n",
    "\n",
    "print(\"Target Column Name:: {} \\n\".format(fileData.__dataframe__().column_names()[-1]))\n",
    "\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "'''\n",
    "# Undersample the majority class\n",
    "X_train, y_train = rus.fit_resample(X_train, y_train)\n",
    "X_test, y_test = rus.fit_resample(X_test, y_test)\n",
    "'''\n",
    "\n",
    "# Oversample the minority class using SMOTE\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "#X_test, y_test = rus.fit_resample(X_test, y_test)\n",
    "X_test, y_test = smote.fit_resample(X_test, y_test) \n",
    "\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "#Y_train_scaled = scaler.transform(y_train)\n",
    "#Y_test_scaled = scaler.transform(y_test)\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "print(\"\\n X Train: Shape:: {}\".format(X_train.shape))\n",
    "print(\" X Test: Shape:: {}\".format(X_test.shape))  \n",
    " \n",
    " \n",
    "positiveClass =  0\n",
    "negativeClass = 0\n",
    "for i in y_train:\n",
    "    if(i == 0):\n",
    "        negativeClass += 1\n",
    "    if(i == 1):\n",
    "        positiveClass += 1\n",
    "print(\"Train DataSet Positive Class Records:: {}\".format(positiveClass)) \n",
    "print(\"Train DataSet Negative Class Records:: {}\".format(negativeClass)) \n",
    "print(\"Train DataSet Total Records:: {}\".format(positiveClass + negativeClass)) \n",
    "\n",
    "print(\"\\n\\n\") \n",
    "\n",
    "\n",
    "positiveClass =  0\n",
    "negativeClass = 0\n",
    "for i in y_test:\n",
    "    if(i == 0):\n",
    "        negativeClass += 1\n",
    "    if(i == 1):\n",
    "        positiveClass += 1\n",
    "print(\"Test DataSet Positive Class Records:: {}\".format(positiveClass)) \n",
    "print(\"Test DataSet Negative Class Records:: {}\".format(negativeClass)) \n",
    "print(\"Test DataSet Total Records:: {}\".format(positiveClass + negativeClass)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCorrelationPic(correlationMatrix, numberOfTopFeatures, targetColumnName):     \n",
    "    correlation_values = correlationMatrix.abs()\n",
    "    sorted_correlation = correlation_values.unstack().sort_values(ascending=False)\n",
    "    sorted_correlation = sorted_correlation[sorted_correlation != 1.0]\n",
    "\n",
    "    num_features = numberOfTopFeatures  # Number of top features to display\n",
    "    top_features = sorted_correlation.head(num_features)\n",
    "    print(\"Top\", num_features, \"features based on correlation:\")\n",
    "    print(top_features)\n",
    " \n",
    "    top_features = correlationMatrix.abs().nlargest(numberOfTopFeatures, targetColumnName)[targetColumnName].index\n",
    "    top_correlation_matrix = correlationMatrix.loc[top_features, top_features]\n",
    "\n",
    "    mplot.figure(figsize=(10, 8))\n",
    "    sns.heatmap(top_correlation_matrix, annot=True, cmap='coolwarm')\n",
    "    # Set the title of the plot\n",
    "    mplot.title('Correlation Heatmap ({})'.format(dataSetName))\n",
    "    \n",
    "    picturePath = \"Correlation_Matrix_DateSetName_{}.png\".format(dataSetName)\n",
    "    mplot.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "    mplot.show()\n",
    "    mplot.close()\n",
    "\n",
    "def makeConfusionMatrixPic(method, dataSet, classifierObj , X_test, y_test, predicted_Y):\n",
    "    display = ConfusionMatrixDisplay.from_estimator(classifierObj, X_test, y_test, display_labels=['Healthy', \"Heart Disease\"], cmap=mplot.cm.Blues) #, normalize=\"true\"\n",
    "    display.ax_.set_title(\"Confusion Matrix ({} Model)\".format(method))\n",
    "    display.ax_.set_xlabel('\\nPredicted Values')\n",
    "    display.ax_.set_ylabel('Actual Values ')\n",
    "\n",
    "\n",
    "    accuracyString =\"Accuracy {}: {:.2f}\".format(method, accuracy_score(y_test, predicted_Y)*100.0 ) \n",
    "    recallString =  'Recall {}: {:.2f}'.format(method, recall_score(y_test, predicted_Y) * 100.0)\n",
    "    precisionString = 'Precision {}: {:.2f}'.format(method, precision_score(y_test, predicted_Y) * 100.0) \n",
    "    dataSetString = \"Dataset: {}\".format(dataSet)\n",
    "\n",
    "    \n",
    "    if(classifierObj.n_features_in_ > 10):\n",
    "        featureListString = 'Total Features: {}'.format(classifierObj.n_features_in_) \n",
    "    else:\n",
    "        featureListString = 'Features: {}'.format(classifierObj.feature_names_in_) \n",
    "    \n",
    "    display.figure_.text(0.010, -0.05,  accuracyString, horizontalalignment='left', wrap=False )  \n",
    "    display.figure_.text(0.010, -0.09,  recallString, horizontalalignment='left', wrap=False )      \n",
    "    display.figure_.text(0.010, -0.13,  precisionString, horizontalalignment='left', wrap=False ) \n",
    "    display.figure_.text(0.010, -0.17,  dataSetString, horizontalalignment='left', wrap=False ) \n",
    "    display.figure_.text(0.010, -0.28,  featureListString, horizontalalignment='left', wrap=False ) \n",
    " \n",
    "    picturePath = \"{}Confusion_Matrix_{}_{}.png\".format(dataSetResultDirectory, method, dataSetName)\n",
    "    mplot.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "    #print(\"{} Confusion Matrix saved:: path: {}\".format(method, picturePath))\n",
    "    #os.startfile(picturePath)\n",
    "    mplot.show()\n",
    "    mplot.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "# Convert the data to PyTorch tensors\n",
    "X_train_np = X_train.to_numpy()  # Convert DataFrame to NumPy array\n",
    "X_train_tensor = torch.tensor(X_train_np, dtype=torch.float32).cuda()\n",
    "scaler = StandardScaler()\n",
    "X_train_scaler = scaler.fit_transform(X_train)\n",
    "X_test_scaler = scaler.fit_transform(X_test) \n",
    "X_train_f32 = np.asarray(X_train).astype(np.float32)  #.astype('float32').reshape((-1,1))\n",
    "X_test_f32 = np.asarray(X_test).astype(np.float32)\n",
    "#y_train_scaler = np.asarray(y_train).astype('float32').reshape((-1,1))\n",
    "y_test_scaler = np.asarray(y_test).astype('float32').reshape((-1,1))\n",
    "features = X_train_scaler # data.iloc[:, :-1]\n",
    "target = np.asarray(y_train).astype('float64').reshape((-1,1))  #data['CoronaryHeartDisease'] \n",
    "y_train_tensor = torch.tensor(target, dtype=torch.float32).view(-1, 1).cuda()\n",
    "\n",
    "'''\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train.to_numpy(), dtype=torch.float32).cuda()\n",
    "y_train_tensor = torch.tensor(y_train.to_numpy(), dtype=torch.float32).cuda()\n",
    "X_test_tensor = torch.tensor(X_test.to_numpy(), dtype=torch.float32).cuda()\n",
    "y_test_tensor = torch.tensor(y_test.to_numpy(), dtype=torch.float32).cuda()\n",
    "#print(X_train_tensor)\n",
    "#print(y_train_tensor) \n",
    "# Define a custom dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "    \n",
    "train_dataset = CustomDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = CustomDataset(X_test_tensor, y_test_tensor)\n",
    "print(train_dataset)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "print(train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (49798, 50)   and dType: 50\n",
      "y_train shape: (49798,)   and dType: int64\n",
      "X_train_tensor shape: torch.Size([49798, 50])   and dType: torch.float32\n",
      "y_train_tensor shape: torch.Size([49798])   and dType: torch.float32\n",
      "X_test_tensor shape: torch.Size([21344, 50])   and dType: torch.float32\n",
      "y_test_tensor shape: torch.Size([21344])   and dType: torch.float32\n",
      "features shape: torch.Size([49798, 50])   and dType: torch.float32\n",
      "target shape: torch.Size([49798])   and dType: torch.float32\n"
     ]
    }
   ],
   "source": [
    " \n",
    "features = X_train_tensor \n",
    "target = y_train_tensor\n",
    " \n",
    "  \n",
    "print(\"X_train shape: {}   and dType: {}\".format(X_train.shape, len(X_train.columns)))\n",
    "print(\"y_train shape: {}   and dType: {}\".format(y_train.shape, y_train.dtype))  \n",
    "\n",
    "print(\"X_train_tensor shape: {}   and dType: {}\".format(X_train_tensor.shape, X_train_tensor.dtype))\n",
    "print(\"y_train_tensor shape: {}   and dType: {}\".format(y_train_tensor.shape, y_train_tensor.dtype)) \n",
    "\n",
    "\n",
    "print(\"X_test_tensor shape: {}   and dType: {}\".format(X_test_tensor.shape, X_test_tensor.dtype))\n",
    "print(\"y_test_tensor shape: {}   and dType: {}\".format(y_test_tensor.shape, y_test_tensor.dtype)) \n",
    "\n",
    "\n",
    "\n",
    "print(\"features shape: {}   and dType: {}\".format(features.shape, features.dtype))\n",
    "print(\"target shape: {}   and dType: {}\".format(target.shape, target.dtype)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    " \n",
    "\n",
    "# Define the attention layer\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=input_size // 2, num_heads=1)\n",
    "    def forward(self, q, v):\n",
    "        attention_weights, _ = self.attention(q.unsqueeze(0), v.unsqueeze(0), v.unsqueeze(0))\n",
    "        return attention_weights.squeeze(0)\n",
    "    \n",
    "\n",
    "# Define the model\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, input_size): \n",
    "        super(CustomModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, input_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(input_size)\n",
    "        self.fc2 = nn.Linear(input_size, input_size // 2)\n",
    "        self.attention = AttentionLayer(input_size)\n",
    "        self.fc3 = nn.Linear(input_size, input_size // 2)  # Adjusted input_size here\n",
    "        self.batch_norm2 = nn.BatchNorm1d(input_size // 2)\n",
    "        self.output_layer = nn.Linear(input_size // 2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Traditional neural network part \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.fc2(x)\n",
    "        # Attention layer\n",
    "        attention = self.attention(x, x)\n",
    "        # Combine the output of the attention layer with the previous layer\n",
    "        x = torch.cat([x, attention], dim=1)\n",
    "        # Another dense layer\n",
    "        x = self.fc3(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        # Output layer\n",
    "        x = self.output_layer(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "input_size = X_train_tensor.shape[1]  # Assuming 'features' is a torch tensor\n",
    "print(input_size)\n",
    "model = CustomModel(input_size).cuda()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()\n",
    " \n",
    "# Training the model\n",
    "numberOfEpochs = 20\n",
    "batchSizeOfTraining = 25 \n",
    "\n",
    "for epoch in range(numberOfEpochs):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X_train_tensor)\n",
    "    \n",
    "    # Assuming y_train_tensor is of shape [49798, 1]\n",
    "    # If not, make sure to reshape it to have the same shape as the output\n",
    "    loss = criterion(output, y_train_tensor.view(-1, 1))  # Ensure y_train_tensor has shape [49798, 1]\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.6756048202514648\n",
      "Test accuracy: 0.4999999701976776\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    y_pred = model(X_test_tensor)\n",
    "    loss = criterion(y_pred, y_test_tensor.view(-1, 1))\n",
    "    accuracy = ((y_pred > 0.5) == y_test_tensor.byte()).float().mean().item()\n",
    "\n",
    "# Print the results\n",
    "print('Test loss: {}'.format(loss.item()))\n",
    "print('Test accuracy: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21344\n"
     ]
    }
   ],
   "source": [
    "print(len(y_pred))\n",
    "print(len(y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.47      0.56     10672\n",
      "         1.0       0.59      0.77      0.67     10672\n",
      "\n",
      "    accuracy                           0.62     21344\n",
      "   macro avg       0.63      0.62      0.61     21344\n",
      "weighted avg       0.63      0.62      0.61     21344\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    " \n",
    "y_test_cpu = y_test_tensor.cpu().numpy()\n",
    "\n",
    "# Convert to binary predictions (assuming binary classification)\n",
    "binary_predictions = [1 if pred > 0.5 else 0 for pred in y_pred]\n",
    "\n",
    "# Draw confusion matrix\n",
    "cm = confusion_matrix(y_test_cpu, binary_predictions)\n",
    "mplot.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "mplot.xlabel(\"Predicted\")\n",
    "mplot.ylabel(\"True\")\n",
    "picturePath = \"{}Confusion_Matrix_{}_{}.png\".format(dataSetResultDirectory, \"MLP+Attention\", dataSetName)\n",
    "mplot.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "mplot.show()\n",
    "mplot.close()\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test_cpu, binary_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m true_labels \u001b[38;5;241m=\u001b[39m y_test_tensor\u001b[38;5;241m.\u001b[39mcuda()  \u001b[38;5;66;03m# [\"Healthy\", \"Heart Patient\"]\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Draw confusion matrix\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m cm \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m mplot\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m      7\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(cm, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m\"\u001b[39m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBlues\u001b[39m\u001b[38;5;124m\"\u001b[39m, cbar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m     ):\n\u001b[1;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:326\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m    232\u001b[0m     {\n\u001b[0;32m    233\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    242\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    243\u001b[0m ):\n\u001b[0;32m    244\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \n\u001b[0;32m    246\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;124;03m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 326\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[1;32mc:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:85\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;124;03my_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     84\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[1;32m---> 85\u001b[0m type_true \u001b[38;5;241m=\u001b[39m \u001b[43mtype_of_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my_true\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     88\u001b[0m y_type \u001b[38;5;241m=\u001b[39m {type_true, type_pred}\n",
      "File \u001b[1;32mc:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\multiclass.py:311\u001b[0m, in \u001b[0;36mtype_of_target\u001b[1;34m(y, input_name)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse_pandas:\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my cannot be class \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSparseSeries\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSparseArray\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_multilabel\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-indicator\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;66;03m# DeprecationWarning will be replaced by ValueError, see NEP 34\u001b[39;00m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;66;03m# https://numpy.org/neps/nep-0034-infer-dtype-is-object.html\u001b[39;00m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;66;03m# We therefore catch both deprecation (NumPy < 1.24) warning and\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;66;03m# value error (NumPy >= 1.24).\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\multiclass.py:167\u001b[0m, in \u001b[0;36mis_multilabel\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    165\u001b[0m warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m, VisibleDeprecationWarning)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 167\u001b[0m     y \u001b[38;5;241m=\u001b[39m check_array(y, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_kwargs)\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (VisibleDeprecationWarning, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:915\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    913\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 915\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    917\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    918\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    919\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    378\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 380\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[1;32mc:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:1030\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1028\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1030\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1032\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert to binary predictions (assuming binary classification)\n",
    "binary_predictions = [1 if pred > 0.5 else 0 for pred in y_pred]\n",
    "true_labels = y_test_tensor.cuda()  # [\"Healthy\", \"Heart Patient\"]\n",
    "# Draw confusion matrix\n",
    "cm = confusion_matrix(y_test_tensor, y_pred)\n",
    "mplot.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "mplot.xlabel(\"Predicted\")\n",
    "mplot.ylabel(\"True\")\n",
    "mplot.show()\n",
    "mplot.close()\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test_tensor, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':16:8'\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        predictions.extend(outputs.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Convert to binary predictions (assuming binary classification)\n",
    "binary_predictions = [1 if pred > 0.5 else 0 for pred in predictions]\n",
    "\n",
    "# Draw confusion matrix\n",
    "cm = confusion_matrix(true_labels, binary_predictions)\n",
    "mplot.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "mplot.xlabel(\"Predicted\")\n",
    "mplot.ylabel(\"True\")\n",
    "mplot.show()\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(true_labels, binary_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
