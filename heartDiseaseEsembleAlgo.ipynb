{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as mplot\n",
    "from matplotlib.colors import ListedColormap\n",
    "import os\n",
    "import subprocess\n",
    "import sklearn\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score, f1_score, precision_score, recall_score,  precision_recall_fscore_support\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "import shap\n",
    "import lime\n",
    "from lime import lime_tabular\n",
    "import random\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "import seaborn as sns\n",
    "\n",
    "from tabulate import tabulate\n",
    "from xgboost import XGBClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSetIndex = 6\n",
    "needToMakePictureOfTrees = 0\n",
    "''' ---------------------------------------------------------- '''\n",
    "dataSetFilePath = \"\"\n",
    "dataSetName = \"\"\n",
    "dataSetResultDirectory = \"./\"\n",
    "\n",
    "if(dataSetIndex == 0):\n",
    "    dataSetFilePath = \"./heartDisease/0_statLog_dataSet.csv\"\n",
    "    dataSetName = \"SateLog_DataSet\"\n",
    "elif (dataSetIndex == 1):\n",
    "    dataSetFilePath = \"./heartDisease/1_heart_statlog_cleveland_hungary_final.csv\"\n",
    "    dataSetName = \"ALL_StateLog_CleveLand_Hungary\"\n",
    "elif (dataSetIndex == 2):\n",
    "    dataSetFilePath = \"./heartDisease/2_cleveland.csv\"\n",
    "    dataSetName = \"Cleveland\"\n",
    "elif (dataSetIndex == 3):\n",
    "    dataSetFilePath = \"./heartDisease/3_framingham.csv\"\n",
    "    dataSetName = \"framingham\"\n",
    "elif (dataSetIndex == 4):\n",
    "    dataSetFilePath = \"./heartDisease/4_CardiacPrediction.xlsx\"\n",
    "    dataSetName = \"CardiacPrediction\"\n",
    "elif (dataSetIndex == 5):\n",
    "    dataSetFilePath = \"./heartDisease/5_CardiacPredictionLessDimensions.xlsx\"\n",
    "    dataSetName = \"CardiacPrediction\"\n",
    "elif (dataSetIndex == 6):\n",
    "    dataSetFilePath = \"./heartDisease/6_CardiacPredictionFewDimensions.xlsx\"\n",
    "    dataSetName = \"CardiacPrediction\"\n",
    "else:\n",
    "    dataSetFilePath = \"\"\n",
    "    dataSetName = \"\"\n",
    "\n",
    "if(dataSetIndex==4 or dataSetIndex==5 or dataSetIndex==6):\n",
    "    #fileData = pd.read_excel(dataSetFilePath, sheet_name='CoroHeartDis')\n",
    "    fileData = pd.read_excel(dataSetFilePath)\n",
    "else:\n",
    "    fileData = pd.read_csv(dataSetFilePath)\n",
    "\n",
    "#print(\"Shape of fileData: {}\".format(fileData.shape))\n",
    "#print(\"Column Headings: {}\".format(fileData.__dataframe__().column_names()))\n",
    "#print(\"Number of Records: {}\".format(fileData.__dataframe__().num_rows()))\n",
    "\n",
    "\n",
    "\n",
    "num_rows_before = fileData.shape[0] \n",
    "fileData.drop_duplicates(inplace=True) \n",
    "num_rows_after = fileData.shape[0] \n",
    "num_duplicates_removed = num_rows_before - num_rows_after\n",
    "print(f\"Number of duplicate records removed: {num_duplicates_removed}\")\n",
    " \n",
    " # Preprocess Steps from the ChatGPT\n",
    "# 1. Handling Missing Values:\n",
    "fileData = fileData.dropna()\n",
    "print(\"Shape of fileData: {}\".format(fileData.shape))              \n",
    "#fileData.replace({'?': np.nan}).dropna().astype(float)\n",
    "#fileData = fileData.fillna(0)\n",
    "\n",
    "'''\n",
    "for columnName in fileData.__dataframe__().column_names():\n",
    "    #print(\"Column Name: {}, Len:{} \".format(columnName,len(fileData[columnName]))) \n",
    "    fileData[columnName] = np.floor(pd.to_numeric(fileData[columnName], errors='coerce')).astype('Int64') \n",
    "    meanValue = np.mean(fileData[columnName])\n",
    "    print(\"Column Name: {}, means:{} \".format(columnName, meanValue))\n",
    "    for i in range( len(fileData[columnName]) ):\n",
    "        print(\"----> Column Name: {}, Index:{} , Value:{} \".format(columnName, i, (fileData[columnName][i]) ))\n",
    "            #print(\"%%%%----> Column Name: {}, Index:{} , Value:{} \\n\\n\".format(columnName, i, str(fileData[columnName][i]) ))\n",
    "            fileData[columnName][i] = meanValue\n",
    "'''\n",
    "\n",
    "fileData = fileData.fillna(0)\n",
    "# 2. Handling Outliers:\n",
    "# 3. Feature Scaling:\n",
    "# 4. Encoding Categorical Variables:\n",
    "# 5. Feature Engineering:\n",
    "# 6. Handling Skewed Distributions:\n",
    "# 7. Dimensionality Reduction:\n",
    "# 8. Handling Imbalanced Classes:\n",
    "# 9. Normalization of Data:\n",
    "# 10. Data Splitting:\n",
    "\n",
    "print(\"Shape of fileData End: {}\".format(fileData.shape))\n",
    "\n",
    "\n",
    "\n",
    "dataSetResultDirectory += dataSetName\n",
    "dataSetResultDirectory += \"DataSetResult/\"\n",
    "if not os.path.isdir(dataSetResultDirectory):\n",
    "    os.makedirs(dataSetResultDirectory)\n",
    "\n",
    "dataSetName += \" {}\".format(fileData.shape)\n",
    "\n",
    "if(dataSetIndex == 0): \n",
    "    X = fileData[['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal']]  # Features\n",
    "    Y = fileData['target']  # Labels\n",
    "elif (dataSetIndex == 1): \n",
    "    #X = fileData[['age', 'sex', 'chest pain type', 'resting bp s', 'cholesterol', 'fasting blood sugar', 'resting ecg', 'max heart rate', 'exercise angina', 'oldpeak', 'ST slope']]  # Features\n",
    "    X = fileData[['fasting blood sugar', 'resting ecg', 'max heart rate', 'exercise angina', 'oldpeak']]  # Features LIME KNN\n",
    "    Y = fileData['target']  # Labels\n",
    "elif(dataSetIndex == 2): \n",
    "    X = fileData[['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal']]  # Features\n",
    "    Y = fileData['target']  # Labels\n",
    "elif(dataSetIndex == 3): \n",
    "    X = fileData.drop('TenYearCHD', axis=1)  # Features\n",
    "    Y = fileData['TenYearCHD']  # Labels\n",
    "elif(dataSetIndex == 4): \n",
    "    X = fileData.drop('CoronaryHeartDisease', axis=1)  # Features\n",
    "    Y = fileData['CoronaryHeartDisease']  # Labels\n",
    "else: \n",
    "    X = fileData.drop('CoronaryHeartDisease', axis=1)  # Features\n",
    "    Y = fileData['CoronaryHeartDisease']  # Labels\n",
    "\n",
    "\n",
    "\n",
    "#print(\"\\n\")\n",
    "#print(\"columns of x:: {} \\n\\n and features of X: {}\".format(len(X.columns), X.columns))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileData.hist(figsize=(10, 8))\n",
    "mplot.tight_layout()\n",
    "mplot.show()\n",
    "mplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = fileData.__dataframe__().column_names() \n",
    "totalRecords = (fileData.__dataframe__().num_rows())\n",
    "columnsForGraph = []\n",
    "columnsForGraph.clear()\n",
    "tableDataRow = []\n",
    "for column in columns:\n",
    "    singleColumnCount = fileData[column].value_counts()\n",
    "    if(len(singleColumnCount) < 3):\n",
    "        #print('Column Name:{} -> total records:{}'.format(column, totalRecords ) )\n",
    "        #print('Number of classes:', len(singleColumnCount))\n",
    "        #print('Class distribution:')\n",
    "        #print(singleColumnCount)\n",
    "        #print(\"np Array: {}\".format(np.array(singleColumnCount)))\n",
    "        #print(\"index: 0: {} -> {} %\".format(np.array(singleColumnCount)[0], (np.array(singleColumnCount)[0] /totalRecords) * 100))\n",
    "        #print(\"index: 1: {} -> {} %\".format(np.array(singleColumnCount)[1], ( np.array(singleColumnCount)[1] /totalRecords) * 100))  \n",
    "        #print('---------------------------------------------------------------')\n",
    "        columnsForGraph.append(column)\n",
    " \n",
    "\n",
    "tableDataRow = [\n",
    "    ['Index', 'Column Name', 'Total Classes','Class A Records','Class B Records'],\n",
    "    \n",
    "]\n",
    "\n",
    "indexx = 1\n",
    "for column in columnsForGraph:\n",
    "    singleColumnCount = fileData[column].value_counts()\n",
    "    singleRowInTable = [] \n",
    "    singleRowInTable.append(indexx)\n",
    "    singleRowInTable.append(column)\n",
    "    singleRowInTable.append(len(singleColumnCount))\n",
    "    cellDataString = \"{} -> {:.2f}%\".format(np.array(singleColumnCount)[0], (np.array(singleColumnCount)[0] /totalRecords) * 100)\n",
    "    singleRowInTable.append((cellDataString)) \n",
    "    cellDataString = \"{} -> {:.2f}%\".format(np.array(singleColumnCount)[1], (np.array(singleColumnCount)[1] /totalRecords) * 100)\n",
    "    singleRowInTable.append((cellDataString)) \n",
    "    indexx += 1\n",
    "    tableDataRow.append(singleRowInTable) \n",
    "\n",
    "# Create the figure and axes\n",
    "fig, ax = mplot.subplots() \n",
    "table = mplot.table(cellText=tableDataRow, loc='center') \n",
    "\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(12) \n",
    "table.scale(2.0, 2.0)\n",
    "\n",
    "#mplot.subplot(1, 2, 2)\n",
    "#mplot.text(0.5, 0.5, f\"The column with the most records per class is: {max_count_column}\", fontweight='bold', fontsize=12)\n",
    "\n",
    "\n",
    "print(\"Target Column Name: {}\".format(columns[-1]))\n",
    "\n",
    "\n",
    "dataSetString = \"Dataset:  {}, Total Records: {}, No. Features: {}\".format(dataSetName, totalRecords, fileData.__dataframe__().num_columns())\n",
    "target =\"Target Column Name: {} , No of Classes: {}\".format(columns[-1], len(fileData[columns[-1]].value_counts()))\n",
    "distributionOfTargetClassA =\"Class A Records: {} , {:.2f} %\".format(np.array(fileData[columns[-1]].value_counts())[0], (np.array(fileData[columns[-1]].value_counts())[0] /totalRecords) * 100)\n",
    "distributionOfTargetClassB =\"Class B Records: {} , {:.2f} %\".format(np.array(fileData[columns[-1]].value_counts())[1], (np.array(fileData[columns[-1]].value_counts())[1] /totalRecords) * 100)\n",
    "\n",
    "fig.text(-0.1, +0.25,  dataSetString, horizontalalignment='left', wrap=False , fontsize=12 )  \n",
    "fig.text(-0.1, +0.20,  target, horizontalalignment='left', wrap=False  , fontsize=12 )   \n",
    "fig.text(-0.1, 0.15,  distributionOfTargetClassA, horizontalalignment='left', wrap=False , fontsize=12  )   \n",
    "fig.text(-0.1, 0.10,  distributionOfTargetClassB, horizontalalignment='left', wrap=False  , fontsize=12 )   \n",
    "\n",
    "\n",
    "remarks = \"You need to distribute the target class in equal number of records in training-set.\"\n",
    "fig.text(-0.2, -0.0,  remarks, horizontalalignment='left', wrap=True ,fontsize=12, fontweight='bold' )   \n",
    " \n",
    "mplot.axis('off')\n",
    "mplot.title(f'Exploring Dataset - {dataSetName}' ,fontsize=16, fontweight='bold') \n",
    "\n",
    "picturePath = \"{}1.DataSet_analysis_{}.png\".format(dataSetResultDirectory, dataSetName)\n",
    "mplot.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "#mplot.savefig('DataSet_analysis.png', dpi=300)\n",
    "mplot.show()\n",
    "mplot.close()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"columns of x:: {} \\n\\n and features of X: {}\".format(len(X.columns), X.columns))\n",
    " \n",
    "print(\"***************************************\") \n",
    "\n",
    "print(\"Shape of fileData: {} , target Len:{}\".format(fileData.shape, len(Y)))\n",
    "print(\"X: {} , Y:{}\".format(X.shape, Y.shape))\n",
    "#print(\"\\n\\nX: head:: \\n{}\".format(X.head()))\n",
    "#print(\"\\n\\nY: head::\\n {}\".format(Y.head()))\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3) # 70% training and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=12)\n",
    "\n",
    "\n",
    "print(\"\\n X Train: Shape::\\n {}\".format(X_train.shape))\n",
    "print(\"\\n X Train: head::\\n {}\".format(X_train.columns))\n",
    "print(\"\\n X Test: head:: \\n{}\".format(X_test.columns))\n",
    "print(\"\\n Y Train: shape::\\n {}\".format(y_train.shape)) \n",
    "print(\"\\n Y Test: shape::\\n {}\".format(y_test.shape)) \n",
    " \n",
    "instance = np.array(X_test)  # Example: explaining the first instance in the dataset\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCorrelationPic(correlationMatrix, numberOfTopFeatures, targetColumnName):     \n",
    "    correlation_values = correlationMatrix.abs()\n",
    "    sorted_correlation = correlation_values.unstack().sort_values(ascending=False)\n",
    "    sorted_correlation = sorted_correlation[sorted_correlation != 1.0]\n",
    "\n",
    "    num_features = numberOfTopFeatures  # Number of top features to display\n",
    "    top_features = sorted_correlation.head(num_features)\n",
    "    print(\"Top\", num_features, \"features based on correlation:\")\n",
    "    print(top_features)\n",
    " \n",
    "    top_features = correlationMatrix.abs().nlargest(numberOfTopFeatures, targetColumnName)[targetColumnName].index\n",
    "    top_correlation_matrix = correlationMatrix.loc[top_features, top_features]\n",
    "\n",
    "    mplot.figure(figsize=(10, 8))\n",
    "    sns.heatmap(top_correlation_matrix, annot=True, cmap='coolwarm')\n",
    "    # Set the title of the plot\n",
    "    mplot.title('Correlation Heatmap ({})'.format(dataSetName))\n",
    "    \n",
    "    picturePath = \"Correlation_Matrix_DateSetName_{}.png\".format(dataSetName)\n",
    "    mplot.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "    mplot.show()\n",
    "    mplot.close()\n",
    "def plot_classification_report(title, dataSetName, y_tru, y_prd, figsize=(6, 6), ax=None):\n",
    "    #mplot.figure(figsize=figsize)\n",
    "    xticks = ['precision', 'recall', 'f1-score', 'support']\n",
    "    yticks = ['Healthy', 'Heart Disease']\n",
    "    rep = np.array( precision_recall_fscore_support(y_tru, y_prd) ).T\n",
    "    rep[0][0] *= 100.0\n",
    "    rep[0][1] *= 100.0\n",
    "    rep[0][2] *= 100.0\n",
    "    rep[1][0] *= 100.0\n",
    "    rep[1][1] *= 100.0\n",
    "    rep[1][2] *= 100.0\n",
    "    \n",
    "    ax = sns.heatmap(rep, annot=True, cmap='Blues', cbar=False, xticklabels=xticks, yticklabels=yticks)\n",
    "    ax.set_title(\"Classification Report {} Model\\n\\n\".format(title));\n",
    "    ax.set_xlabel('\\nDataset:{}'.format(dataSetName))\n",
    "    ax.xaxis.set_ticklabels(xticks)\n",
    "    ax.set_ylabel('Classes')\n",
    "    ax.yaxis.set_ticklabels(yticks)\n",
    "    \n",
    "    picturePath = \"ClassificationReport_{}_{}.png\".format(title, dataSetName) \n",
    "    mplot.savefig(picturePath, dpi=300, bbox_inches='tight')\n",
    "    #os.startfile(picturePath)\n",
    "    mplot.close()\n",
    "def makeConfusionMatrixPic(method, dataSet, classifierObj , X_test, y_test, predicted_Y):\n",
    "    display = ConfusionMatrixDisplay.from_estimator(classifierObj, X_test, y_test, display_labels=['Healthy', \"Heart Disease\"], cmap=mplot.cm.Blues) #, normalize=\"true\"\n",
    "    display.ax_.set_title(\"Confusion Matrix ({} Model)\".format(method))\n",
    "    display.ax_.set_xlabel('\\nPredicted Values')\n",
    "    display.ax_.set_ylabel('Actual Values ')\n",
    "\n",
    "\n",
    "    accuracyString =\"Accuracy {}: {:.2f}\".format(method, accuracy_score(y_test, predicted_Y)*100.0 ) \n",
    "    recallString =  'Recall {}: {:.2f}'.format(method, recall_score(y_test, predicted_Y) * 100.0)\n",
    "    precisionString = 'Precision {}: {:.2f}'.format(method, precision_score(y_test, predicted_Y) * 100.0) \n",
    "    dataSetString = \"Dataset: {}\".format(dataSet)\n",
    "\n",
    "    \n",
    "    if(classifierObj.n_features_in_ > 10):\n",
    "        featureListString = 'Total Features: {}'.format(classifierObj.n_features_in_) \n",
    "    else:\n",
    "        featureListString = 'Features: {}'.format(classifierObj.feature_names_in_) \n",
    "    \n",
    "    display.figure_.text(0.010, -0.05,  accuracyString, horizontalalignment='left', wrap=False )  \n",
    "    display.figure_.text(0.010, -0.09,  recallString, horizontalalignment='left', wrap=False )      \n",
    "    display.figure_.text(0.010, -0.13,  precisionString, horizontalalignment='left', wrap=False ) \n",
    "    display.figure_.text(0.010, -0.17,  dataSetString, horizontalalignment='left', wrap=False ) \n",
    "    display.figure_.text(0.010, -0.28,  featureListString, horizontalalignment='left', wrap=False ) \n",
    " \n",
    "    picturePath = \"{}Confusion_Matrix_{}_{}.png\".format(dataSetResultDirectory, method, dataSetName)\n",
    "    mplot.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "    #print(\"{} Confusion Matrix saved:: path: {}\".format(method, picturePath))\n",
    "    #os.startfile(picturePath)\n",
    "    mplot.show()\n",
    "    mplot.close()\n",
    "def makeLIMEreport(method, classifierObj):\n",
    "    class_names =  ['Healthy', 'Heart Disease']\n",
    "    listOfFeatures =  classifierObj.feature_names_in_\n",
    "    print(\"\\n\\n\\n Obj Features: {}, len: {} \\n\\n\".format(listOfFeatures, len(listOfFeatures)))\n",
    "    #explainer = lime_tabular.LimeTabularExplainer(np.array(X_train) , mode='regression', feature_names=listOfFeatures, verbose=True, class_names=class_names )\n",
    "    explainer = lime_tabular.LimeTabularExplainer(np.array(X_train) , mode='classification', feature_names=listOfFeatures, verbose=True, class_names=class_names )\n",
    "\n",
    "    num_instances = int(len(X_test)/4)\n",
    "    print(\"num_instances: {}\".format(num_instances))\n",
    "    # Generate explanations for each testing instance\n",
    "    explanations = []\n",
    "    for i in range(num_instances):\n",
    "        instan = instance[i]\n",
    "        explanation = explainer.explain_instance(instan, classifierObj.predict_proba, num_features=len(instan))\n",
    "        explanations.append(explanation)\n",
    "\n",
    "    #Extract the feature importance values from the explanations\n",
    "    feature_importances = np.mean([exp.as_map()[1] for exp in explanations], axis=0)\n",
    "    averageF = []\n",
    "    for singleFeature in feature_importances:\n",
    "        averageF.append(singleFeature[0])\n",
    "     \n",
    "    print(\"\\n\\nfeature_list:{}\".format(listOfFeatures))\n",
    "    print(\"averageF:{} \\n\\n\".format(averageF))\n",
    "\n",
    "\n",
    "    fig, ax = mplot.subplots()\n",
    "    ax.barh(listOfFeatures, averageF )\n",
    "    ax.set_ylabel('Feature List')\n",
    "    ax.set_xlabel('Average Importance')\n",
    "    ax.set_title(\"XAI LIME ({} Model)\".format(method))\n",
    "     \n",
    "    dataSetString = \"Dataset:  {}\".format(dataSetName)\n",
    "    testingDatasetString =\"length of Testing Set: {}\".format(len(X_test))\n",
    "    explainerModelString = \"LIME Explainer Model: {}\".format(explainer.mode)\n",
    "    ax.figure.text(0.020, -0.05,  dataSetString, horizontalalignment='left', wrap=False )  \n",
    "    ax.figure.text(0.020, -0.09,  testingDatasetString, horizontalalignment='left', wrap=False )   \n",
    "    ax.figure.text(0.020, -0.13,  explainerModelString, horizontalalignment='left', wrap=False )   \n",
    " \n",
    "\n",
    "    picturePath = \"XAI_LIME_{}_{}.png\".format(method, dataSetName)\n",
    "    mplot.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "    #mplot.savefig(picturePath,  dpi=300) \n",
    "    #os.startfile(picturePath)\n",
    "    mplot.show()\n",
    "    mplot.close()\n",
    "def makeSHAPreport(method, model):\n",
    "    shap_explainer = shap.Explainer(model, X_train) \n",
    "    shap_values = shap_explainer.shap_values(X_test)  \n",
    "    shap.summary_plot(shap_values, X_test, show=False)\n",
    "    ax = mplot.gca() \n",
    "    ax.set_title(\"XAI SHAP Explainer ({} Model)\".format(method))     \n",
    "\n",
    "    dataSetString = \"Dataset:  {}\".format(dataSetName)\n",
    "    testingDatasetString =\"length of Testing Set: {}\".format(len(X_test))\n",
    "    shapTypeString =\"SHAP Type: {}\".format(repr(shap_explainer)) \n",
    "    ax.figure.text(0.020, -0.05,  dataSetString, horizontalalignment='left', wrap=False )  \n",
    "    ax.figure.text(0.020, -0.09,  testingDatasetString, horizontalalignment='left', wrap=False )   \n",
    "    ax.figure.text(0.020, -0.13,  shapTypeString, horizontalalignment='left', wrap=False )   \n",
    "\n",
    "    picturePath = \"XAI_SHAP_Explainer_{}_{}.png\".format(method, dataSetName)\n",
    "    mplot.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "    #mplot.savefig(picturePath,  dpi=300) \n",
    "    mplot.show()\n",
    "    #os.startfile(picturePath)\n",
    "    mplot.close()\n",
    "def makeSHAP_KERNELreport(method, model):\n",
    "    shap_explainer = shap.KernelExplainer(model.predict_proba, X_train) \n",
    "    testingShape = X_test[0:10]\n",
    "    shap_values = shap_explainer.shap_values(testingShape)  \n",
    "    shap.summary_plot(shap_values, X_test, show=False)\n",
    "    ax = mplot.gca() \n",
    "    ax.set_title(\"XAI SHAP KernelExplainer ({} Model)\".format(method))     \n",
    "\n",
    "    dataSetString = \"Dataset:  {}\".format(dataSetName)\n",
    "    testingDatasetString =\"length of Testing Set: {}\".format(len(testingShape))\n",
    "    shapTypeString =\"SHAP Type: {}\".format(repr(shap_explainer)) \n",
    "    ax.figure.text(0.020, -0.05,  dataSetString, horizontalalignment='left', wrap=False )  \n",
    "    ax.figure.text(0.020, -0.09,  testingDatasetString, horizontalalignment='left', wrap=False )   \n",
    "    ax.figure.text(0.020, -0.13,  shapTypeString, horizontalalignment='left', wrap=False )   \n",
    "\n",
    "    picturePath = \"XAI_SHAP_KernelExplainer_{}_{}.png\".format(method, dataSetName)\n",
    "    mplot.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "    #mplot.savefig(picturePath,  dpi=300) \n",
    "    mplot.show()\n",
    "    #os.startfile(picturePath)\n",
    "    mplot.close()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the XGBoost model\n",
    "model = XGBClassifier()\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Build the CatBoost model\n",
    "model = CatBoostClassifier()\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the input features to the range [0, 1]\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"X_train_scaled:: {}\".format(X_train_scaled.shape))\n",
    "print(\"X_test_scaled:: {}\".format(X_test_scaled.shape))\n",
    "# Reshape the input features for RNN input shape (samples, timesteps, features)\n",
    "# Assuming each sample in the dataset is a sequence of 10 time steps\n",
    "timesteps = 10\n",
    "X_train_reshaped = np.reshape(X_train_scaled, (X_train_scaled.shape[0], timesteps, X_train_scaled.shape[1]))\n",
    "X_test_reshaped = np.reshape(X_test_scaled, (X_test_scaled.shape[0], timesteps, X_test_scaled.shape[1]))\n",
    "\n",
    "# Build the RNN model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(timesteps, X_train_reshaped.shape[2])))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_reshaped, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
    "print('Test Loss:', loss)\n",
    "print('Test Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix\n",
    "#correlation_matrix = fileData[0:len(X.columns)+1].corr()\n",
    "correlation_matrix = fileData.corr()\n",
    "makeCorrelationPic(correlation_matrix, 15, 'CoronaryHeartDisease') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifierAdaBoost = AdaBoostClassifier(n_estimators=1000, random_state=0)\n",
    "classifierAdaBoost.fit(X_train, y_train)\n",
    "y_PredictionAdaBoost = classifierAdaBoost.predict(X_test)\n",
    "\n",
    "methodName = \"AdaBoostClassifier\"\n",
    "makeConfusionMatrixPic(methodName, dataSetName, classifierAdaBoost , X_test, y_test, y_PredictionAdaBoost)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest\n",
    "classifierRF = RandomForestClassifier(n_estimators=100, random_state = 42)\n",
    "classifierRF.fit(X_train, y_train)\n",
    "y_PredictionRF = classifierRF.predict(X_test)\n",
    "\n",
    "methodName = \"RF\" \n",
    "plot_classification_report(methodName, dataSetName, y_test, y_PredictionRF)  \n",
    "makeConfusionMatrixPic(methodName, dataSetName, classifierRF , X_test, y_test, y_PredictionRF)\n",
    "#makeSHAPreport(methodName, classifierRF)\n",
    "#makeSHAP_KERNELreport(methodName, classifierRF)\n",
    "#makeLIMEreport(methodName, classifierRF)\n",
    "  \n",
    "confusionM_rf = confusion_matrix(y_test, y_PredictionRF)\n",
    "print(\" Random Forest Accuracy:\", accuracy_score(y_test, y_PredictionRF))\n",
    "print(\" Random Forest ConfusionM: \", confusionM_rf)\n",
    "print(\" Random Forest  length of estimators:{}\".format(len(classifierRF.estimators_)))\n",
    "\n",
    "\n",
    "'''\n",
    "folderPath = r'./RandomForestTrees_{}/'.format(dataSetName)\n",
    "print(\"FolderPath:{}\".format(folderPath))\n",
    "if not os.path.isdir(folderPath):\n",
    "    os.makedirs(folderPath)\n",
    "\n",
    "#for indx in range(len(rfClassifier.estimators_)):\n",
    "for indx in range(5):\n",
    "    tree = classifierRF.estimators_[indx]\n",
    "    dot_data = export_graphviz(tree, out_file=None, feature_names=classifierRF.feature_names_in_, rounded=True, precision=1)\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "    picturePath = \"{}tree_{}.png\".format(folderPath, indx)\n",
    "    graph.write_png(picturePath)\n",
    "    print(\"Random Forest Tree Picture Generated:: path:\", picturePath)\n",
    "    #os.startfile(picturePath)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes \n",
    "classifierNB = GaussianNB()\n",
    "classifierNB.fit(X_train, y_train)\n",
    "predicted_NB = classifierNB.predict(X_test)\n",
    "\n",
    "methodName = \"NB\" \n",
    "plot_classification_report(methodName, dataSetName, y_test, predicted_NB)  \n",
    "makeConfusionMatrixPic(methodName, dataSetName, classifierNB , X_test, y_test, predicted_NB)\n",
    "#makeSHAPreport(methodName, classifierNB)\n",
    "#makeSHAP_KERNELreport(methodName, classifierNB)\n",
    "#makeLIMEreport(methodName, classifierNB)\n",
    "  \n",
    "confusionMatric = confusion_matrix(y_test, predicted_NB)\n",
    "print(\"{} ConfusionMatrix: {}\".format(methodName, confusionMatric))\n",
    "print(\"Accuracy {}:  {}\".format(methodName, accuracy_score(y_test, predicted_NB)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticRegression\n",
    "#classifierLR = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,intercept_scaling=1, l1_ratio=None, max_iter=100,multi_class='warn', n_jobs=None, penalty='l2',random_state=0, solver='liblinear', tol=0.0001, verbose=0,warm_start=False)\n",
    "classifierLR = LogisticRegression(solver='liblinear', random_state=0)\n",
    "\n",
    "#classifierLR = LogisticRegression()\n",
    "classifierLR.fit(X_train, y_train)\n",
    "predicted_LR = classifierLR.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(classifierLR.score(X_test, y_test)))\n",
    "\n",
    "methodName = \"LogisticRegression\" \n",
    "plot_classification_report(methodName, dataSetName, y_test, predicted_LR)  \n",
    "makeConfusionMatrixPic(methodName, dataSetName, classifierLR , X_test, y_test, predicted_LR)\n",
    "#makeSHAPreport(methodName, classifierLR)\n",
    "#makeSHAP_KERNELreport(methodName, classifierLR)\n",
    "#makeLIMEreport(methodName, classifierLR)\n",
    " \n",
    "\n",
    "confusionMatric = confusion_matrix(y_test, predicted_LR)\n",
    "print(\"{} ConfusionMatrix: {}\".format(methodName, confusionMatric))\n",
    "print(\"Accuracy {}:  {}\".format(methodName, accuracy_score(y_test, predicted_LR)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "#fpr, tpr, thresholds = roc_curve(y_test, classifierLR.predict_proba(X_test)[:,1])\n",
    "mplot.figure()\n",
    "#mplot.plot(fpr, tpr, label=\"(area = {:.2f})\".format(logit_roc_auc))\n",
    "\n",
    "fprLR, tprLR, threshLR = roc_curve(y_test, classifierLR.predict_proba(X_test)[:,1])\n",
    "#fprSVM, tprSVM, threshSVM = roc_curve(y_test, classifierSVM.predict_proba(X_test)[:,1])\n",
    "fprKNN, tprKNN, threshKNN = roc_curve(y_test, classifierKNN.predict_proba(X_test)[:,1])\n",
    "fprNB, tprNB, threshNB = roc_curve(y_test, classifierNB.predict_proba(X_test)[:,1])\n",
    " \n",
    "    \n",
    "# plotting    \n",
    "mplot.plot(fprLR, tprLR, linestyle='--',color='green', label='Class 1 vs Rest')\n",
    "#mplot.plot(fprSVM, tprSVM, linestyle='--',color='orange', label='Class 0 vs Rest')\n",
    "mplot.plot(fprKNN, tprKNN, linestyle='--',color='blue', label='Class 2 vs Rest')\n",
    "mplot.plot(fprNB, tprNB, linestyle='--',color='red', label='Class 2 vs Rest')\n",
    "mplot.title('Multiclass ROC curve')\n",
    "mplot.xlabel('False Positive Rate')\n",
    "mplot.ylabel('True Positive rate')\n",
    "mplot.legend(loc='best')\n",
    "mplot.savefig('Multiclass ROC',dpi=300);    \n",
    "mplot.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roundValue = 0.0\n",
    "for colName in fileData.__dataframe__().column_names():\n",
    "    fileColData = fileData[colName].astype(\"int\")\n",
    "    roundValue = round(fileData[colName].mean(), 2)\n",
    "\n",
    "    print(\"Column Name: {} -> MeanValue:{}\".format(colName, roundValue))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
