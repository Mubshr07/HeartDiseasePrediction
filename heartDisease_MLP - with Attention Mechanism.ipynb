{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as mplot\n",
    "from matplotlib.colors import ListedColormap\n",
    "import os\n",
    "import subprocess\n",
    "import sklearn\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score, f1_score, precision_score, recall_score,  precision_recall_fscore_support\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    " \n",
    "import random\n",
    " \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import plot_model\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "import seaborn as sns\n",
    "\n",
    "from tabulate import tabulate \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSetIndex = 4\n",
    "needToMakePictureOfTrees = 0\n",
    "''' ---------------------------------------------------------- '''\n",
    "dataSetFilePath = \"\"\n",
    "dataSetName = \"\"\n",
    "dataSetResultDirectory = \"./\"\n",
    "\n",
    "if(dataSetIndex == 0):\n",
    "    dataSetFilePath = \"./heartDisease/0_statLog_dataSet.csv\"\n",
    "    dataSetName = \"SateLog_DataSet\"\n",
    "elif (dataSetIndex == 1):\n",
    "    dataSetFilePath = \"./heartDisease/1_heart_statlog_cleveland_hungary_final.csv\"\n",
    "    dataSetName = \"ALL_StateLog_CleveLand_Hungary\"\n",
    "elif (dataSetIndex == 2):\n",
    "    dataSetFilePath = \"./heartDisease/2_cleveland.csv\"\n",
    "    dataSetName = \"Cleveland\"\n",
    "elif (dataSetIndex == 3):\n",
    "    dataSetFilePath = \"./heartDisease/3_framingham.csv\"\n",
    "    dataSetName = \"framingham\"\n",
    "elif (dataSetIndex == 4):\n",
    "    dataSetFilePath = \"./heartDisease/4_CardiacPrediction.xlsx\"\n",
    "    dataSetName = \"CardiacPrediction\"\n",
    "elif (dataSetIndex == 5):\n",
    "    dataSetFilePath = \"./heartDisease/5_CardiacPredictionLessDimensions.xlsx\"\n",
    "    dataSetName = \"CardiacPrediction\"\n",
    "elif (dataSetIndex == 6):\n",
    "    dataSetFilePath = \"./heartDisease/6_CardiacPredictionFewDimensions.xlsx\"\n",
    "    dataSetName = \"CardiacPrediction\"\n",
    "else:\n",
    "    dataSetFilePath = \"\"\n",
    "    dataSetName = \"\"\n",
    "\n",
    "if(dataSetIndex==4 or dataSetIndex==5 or dataSetIndex==6):\n",
    "    #fileData = pd.read_excel(dataSetFilePath, sheet_name='CoroHeartDis')\n",
    "    fileData = pd.read_excel(dataSetFilePath)\n",
    "else:\n",
    "    fileData = pd.read_csv(dataSetFilePath)\n",
    "\n",
    "print(\"Shape of fileData: {}\".format(fileData.shape))\n",
    "print(\"Column Headings: {}\".format(fileData.__dataframe__().column_names()))\n",
    "print(\"Number of Records: {}\".format(fileData.__dataframe__().num_rows()))\n",
    "\n",
    "\n",
    "missingValues = fileData.isnull().any().sum()\n",
    "print(f\"\\nNumber of Missing Values: {missingValues}\")\n",
    "\n",
    "num_rows_before = fileData.shape[0]\n",
    "# Remove duplicate records based on all columns\n",
    "fileData.drop_duplicates(inplace=True)\n",
    "# Check the number of rows after removing duplicates\n",
    "num_rows_after = fileData.shape[0]\n",
    "# Print the number of duplicate records removed\n",
    "num_duplicates_removed = num_rows_before - num_rows_after\n",
    "print(f\"Number of duplicate records removed: {num_duplicates_removed}\")\n",
    " \n",
    " # Preprocess Steps from the ChatGPT\n",
    "# 1. Handling Missing Values:\n",
    "fileData = fileData.dropna()\n",
    "print(\"Shape of fileData: {}\".format(fileData.shape))              \n",
    "#fileData.replace({'?': np.nan}).dropna().astype(float)\n",
    "#fileData = fileData.fillna(0) \n",
    "\n",
    "fileData = fileData.fillna(0) \n",
    "\n",
    "print(\"Shape of fileData End: {}\".format(fileData.shape))\n",
    "\n",
    "\n",
    "\n",
    "finalResultTable = [ ['Index', 'Method', 'Accuracy %','Recall %','Precision %','F1 Score','AUC'], ]  \n",
    "\n",
    "X = fileData.drop(fileData.__dataframe__().column_names()[-1], axis=1)  # Features\n",
    "Y = fileData[fileData.__dataframe__().column_names()[-1]]  # Labels\n",
    "\n",
    "columns = fileData.__dataframe__().column_names() \n",
    "totalRecords = (fileData.__dataframe__().num_rows())\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"columns of x:: {} \\n\\n and features of X: {}\".format(len(X.columns), X.columns))\n",
    "\n",
    "dataSetResultDirectory = \"./\"\n",
    "dataSetResultDirectory += (\"DatasetResults_MLP_with_AttentionLayers_\" + dataSetName)\n",
    "dataSetResultDirectory += \"/\"\n",
    "if not os.path.isdir(dataSetResultDirectory):\n",
    "    os.makedirs(dataSetResultDirectory)\n",
    "\n",
    "dataSetName += \" {}\".format(fileData.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileData.hist(figsize=(10, 8))\n",
    "mplot.tight_layout()\n",
    "mplot.show()\n",
    "mplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = fileData.__dataframe__().column_names() \n",
    "totalRecords = (fileData.__dataframe__().num_rows())\n",
    "columnsForGraph = []\n",
    "columnsForGraph.clear()\n",
    "tableDataRow = []\n",
    "for column in columns:\n",
    "    singleColumnCount = fileData[column].value_counts()\n",
    "    if(len(singleColumnCount) < 3):\n",
    "        #print('Column Name:{} -> total records:{}'.format(column, totalRecords ) )\n",
    "        #print('Number of classes:', len(singleColumnCount))\n",
    "        #print('Class distribution:')\n",
    "        #print(singleColumnCount)\n",
    "        #print(\"np Array: {}\".format(np.array(singleColumnCount)))\n",
    "        #print(\"index: 0: {} -> {} %\".format(np.array(singleColumnCount)[0], (np.array(singleColumnCount)[0] /totalRecords) * 100))\n",
    "        #print(\"index: 1: {} -> {} %\".format(np.array(singleColumnCount)[1], ( np.array(singleColumnCount)[1] /totalRecords) * 100))  \n",
    "        #print('---------------------------------------------------------------')\n",
    "        columnsForGraph.append(column)\n",
    " \n",
    "\n",
    "tableDataRow = [\n",
    "    ['Index', 'Column Name', 'Total Classes','Class A Records','Class B Records'],\n",
    "    \n",
    "]\n",
    "\n",
    "indexx = 1\n",
    "for column in columnsForGraph:\n",
    "    singleColumnCount = fileData[column].value_counts()\n",
    "    singleRowInTable = [] \n",
    "    singleRowInTable.append(indexx)\n",
    "    singleRowInTable.append(column)\n",
    "    singleRowInTable.append(len(singleColumnCount))\n",
    "    cellDataString = \"{} -> {:.2f}%\".format(np.array(singleColumnCount)[0], (np.array(singleColumnCount)[0] /totalRecords) * 100)\n",
    "    singleRowInTable.append((cellDataString)) \n",
    "    cellDataString = \"{} -> {:.2f}%\".format(np.array(singleColumnCount)[1], (np.array(singleColumnCount)[1] /totalRecords) * 100)\n",
    "    singleRowInTable.append((cellDataString)) \n",
    "    indexx += 1\n",
    "    tableDataRow.append(singleRowInTable) \n",
    "\n",
    "# Create the figure and axes\n",
    "fig, ax = mplot.subplots() \n",
    "table = mplot.table(cellText=tableDataRow, loc='center') \n",
    "\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(12) \n",
    "table.scale(2.0, 2.0) \n",
    "print(\"Target Column Name: {}\".format(columns[-1]))\n",
    "\n",
    "\n",
    "dataSetString = \"Dataset:  {}, Total Records: {}, No. Features: {}\".format(dataSetName, totalRecords, fileData.__dataframe__().num_columns())\n",
    "target =\"Target Column Name: {} , No of Classes: {}\".format(columns[-1], len(fileData[columns[-1]].value_counts()))\n",
    "distributionOfTargetClassA =\"Class A Records: {} , {:.2f} %\".format(np.array(fileData[columns[-1]].value_counts())[0], (np.array(fileData[columns[-1]].value_counts())[0] /totalRecords) * 100)\n",
    "distributionOfTargetClassB =\"Class B Records: {} , {:.2f} %\".format(np.array(fileData[columns[-1]].value_counts())[1], (np.array(fileData[columns[-1]].value_counts())[1] /totalRecords) * 100)\n",
    "\n",
    "fig.text(-0.1, +0.25,  dataSetString, horizontalalignment='left', wrap=False , fontsize=12 )  \n",
    "fig.text(-0.1, +0.20,  target, horizontalalignment='left', wrap=False  , fontsize=12 )   \n",
    "fig.text(-0.1, 0.15,  distributionOfTargetClassA, horizontalalignment='left', wrap=False , fontsize=12  )   \n",
    "fig.text(-0.1, 0.10,  distributionOfTargetClassB, horizontalalignment='left', wrap=False  , fontsize=12 )   \n",
    " \n",
    " \n",
    "mplot.axis('off')\n",
    "mplot.title(f'Exploring Dataset - {dataSetName}' ,fontsize=16, fontweight='bold') \n",
    "\n",
    "picturePath = \"{}1.DataSet_analysis_{}.png\".format(dataSetResultDirectory, dataSetName)\n",
    "mplot.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "#mplot.savefig('DataSet_analysis.png', dpi=300)\n",
    "mplot.show()\n",
    "mplot.close()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of fileData: {} , target Len:{}\".format(fileData.shape, len(Y)))\n",
    "print(\"X: {} , Y:{}\".format(X.shape, Y.shape))\n",
    "#print(\"\\n\\nX: head:: \\n{}\".format(X.head()))\n",
    "#print(\"\\n\\nY: head::\\n {}\".format(Y.head()))\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=42)\n",
    " \n",
    "\n",
    "print(\"Target Column Name:: {} \\n\".format(fileData.__dataframe__().column_names()[-1]))\n",
    "\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "'''\n",
    "# Undersample the majority class\n",
    "X_train, y_train = rus.fit_resample(X_train, y_train)\n",
    "X_test, y_test = rus.fit_resample(X_test, y_test)\n",
    "'''\n",
    "\n",
    "# Oversample the minority class using SMOTE\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "#X_test, y_test = rus.fit_resample(X_test, y_test)\n",
    "X_test, y_test = smote.fit_resample(X_test, y_test) \n",
    "\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n X Train: Shape:: {}\".format(X_train.shape))\n",
    "print(\" X Test: Shape:: {}\".format(X_test.shape))  \n",
    " \n",
    " \n",
    "positiveClass =  0\n",
    "negativeClass = 0\n",
    "for i in y_train:\n",
    "    if(i == 0):\n",
    "        negativeClass += 1\n",
    "    if(i == 1):\n",
    "        positiveClass += 1\n",
    "print(\"Train DataSet Positive Class Records:: {}\".format(positiveClass)) \n",
    "print(\"Train DataSet Negative Class Records:: {}\".format(negativeClass)) \n",
    "print(\"Train DataSet Total Records:: {}\".format(positiveClass + negativeClass)) \n",
    "\n",
    "print(\"\\n\\n\") \n",
    "\n",
    "\n",
    "positiveClass =  0\n",
    "negativeClass = 0\n",
    "for i in y_test:\n",
    "    if(i == 0):\n",
    "        negativeClass += 1\n",
    "    if(i == 1):\n",
    "        positiveClass += 1\n",
    "print(\"Test DataSet Positive Class Records:: {}\".format(positiveClass)) \n",
    "print(\"Test DataSet Negative Class Records:: {}\".format(negativeClass)) \n",
    "print(\"Test DataSet Total Records:: {}\".format(positiveClass + negativeClass)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCorrelationPic(correlationMatrix, numberOfTopFeatures, targetColumnName):     \n",
    "    correlation_values = correlationMatrix.abs()\n",
    "    sorted_correlation = correlation_values.unstack().sort_values(ascending=False)\n",
    "    sorted_correlation = sorted_correlation[sorted_correlation != 1.0]\n",
    "\n",
    "    num_features = numberOfTopFeatures  # Number of top features to display\n",
    "    top_features = sorted_correlation.head(num_features)\n",
    "    print(\"Top\", num_features, \"features based on correlation:\")\n",
    "    print(top_features)\n",
    " \n",
    "    top_features = correlationMatrix.abs().nlargest(numberOfTopFeatures, targetColumnName)[targetColumnName].index\n",
    "    top_correlation_matrix = correlationMatrix.loc[top_features, top_features]\n",
    "\n",
    "    mplot.figure(figsize=(10, 8))\n",
    "    sns.heatmap(top_correlation_matrix, annot=True, cmap='coolwarm')\n",
    "    # Set the title of the plot\n",
    "    mplot.title('Correlation Heatmap ({})'.format(dataSetName))\n",
    "    \n",
    "    picturePath = \"Correlation_Matrix_DateSetName_{}.png\".format(dataSetName)\n",
    "    mplot.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "    mplot.show()\n",
    "    mplot.close()\n",
    "\n",
    "def makeConfusionMatrixPic(method, dataSet, classifierObj , X_test, y_test, predicted_Y):\n",
    "    display = ConfusionMatrixDisplay.from_estimator(classifierObj, X_test, y_test, display_labels=['Healthy', \"Heart Disease\"], cmap=mplot.cm.Blues) #, normalize=\"true\"\n",
    "    display.ax_.set_title(\"Confusion Matrix ({} Model)\".format(method))\n",
    "    display.ax_.set_xlabel('\\nPredicted Values')\n",
    "    display.ax_.set_ylabel('Actual Values ')\n",
    "\n",
    "\n",
    "    accuracyString =\"Accuracy {}: {:.2f}\".format(method, accuracy_score(y_test, predicted_Y)*100.0 ) \n",
    "    recallString =  'Recall {}: {:.2f}'.format(method, recall_score(y_test, predicted_Y) * 100.0)\n",
    "    precisionString = 'Precision {}: {:.2f}'.format(method, precision_score(y_test, predicted_Y) * 100.0) \n",
    "    dataSetString = \"Dataset: {}\".format(dataSet)\n",
    "\n",
    "    \n",
    "    if(classifierObj.n_features_in_ > 10):\n",
    "        featureListString = 'Total Features: {}'.format(classifierObj.n_features_in_) \n",
    "    else:\n",
    "        featureListString = 'Features: {}'.format(classifierObj.feature_names_in_) \n",
    "    \n",
    "    display.figure_.text(0.010, -0.05,  accuracyString, horizontalalignment='left', wrap=False )  \n",
    "    display.figure_.text(0.010, -0.09,  recallString, horizontalalignment='left', wrap=False )      \n",
    "    display.figure_.text(0.010, -0.13,  precisionString, horizontalalignment='left', wrap=False ) \n",
    "    display.figure_.text(0.010, -0.17,  dataSetString, horizontalalignment='left', wrap=False ) \n",
    "    display.figure_.text(0.010, -0.28,  featureListString, horizontalalignment='left', wrap=False ) \n",
    " \n",
    "    picturePath = \"{}Confusion_Matrix_{}_{}.png\".format(dataSetResultDirectory, method, dataSetName)\n",
    "    mplot.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "    #print(\"{} Confusion Matrix saved:: path: {}\".format(method, picturePath))\n",
    "    #os.startfile(picturePath)\n",
    "    mplot.show()\n",
    "    mplot.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normalized = tf.keras.utils.normalize(X_train, axis=1)\n",
    "X_test_normalized = tf.keras.utils.normalize(X_test, axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaler = scaler.fit_transform(X_train)\n",
    "X_test_scaler = scaler.fit_transform(X_test) \n",
    "# Our vectorized labels\n",
    "\n",
    "X_train = np.asarray(X_train).astype(np.float32)  #.astype('float32').reshape((-1,1))\n",
    "X_test = np.asarray(X_test).astype(np.float32)\n",
    "\n",
    "#y_train_scaler = np.asarray(y_train).astype('float32').reshape((-1,1))\n",
    "y_test_scaler = np.asarray(y_test).astype('float32').reshape((-1,1))\n",
    "\n",
    " \n",
    "\n",
    "# Separate features and target variable\n",
    "features = X_train_scaler # data.iloc[:, :-1]\n",
    "target = np.asarray(y_train).astype('float32').reshape((-1,1))  #data['CoronaryHeartDisease']\n",
    " \n",
    " \n",
    "\n",
    "print(\"X_train shape: {}   and dType: {}\".format(X_train.shape, X_train.dtype))\n",
    "print(\"X_train_scaler shape: {}   and dType: {}\".format(X_train_scaler.shape, X_train_scaler.dtype))\n",
    "print(\"X_test_scaler shape: {}   and dType: {}\".format(X_test_scaler.shape, X_test_scaler.dtype)) \n",
    "\n",
    "\n",
    "print(\"y_train shape: {}   and dType: {}\".format(y_train.shape, y_train.dtype))  \n",
    "print(\"y_test_scaler shape: {}   and dType: {}\".format(y_test_scaler.shape, y_test_scaler.dtype))  \n",
    "\n",
    "\n",
    "print(\"features shape: {}   and dType: {}\".format(features.shape, features.dtype))\n",
    "print(\"target shape: {}   and dType: {}\".format(target.shape, target.dtype)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.metrics import AUC, Precision, Recall, F1Score\n",
    "\n",
    "# Define custom metrics\n",
    "recall = Recall()\n",
    "precision = Precision()\n",
    "f1_score = F1Score()\n",
    "auc = AUC()\n",
    "\n",
    "\n",
    "# Transformer Attention Model\n",
    "def transformer_attention_model(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Transformer Encoder Block\n",
    "    attention_output = layers.MultiHeadAttention(num_heads=8, key_dim=64)(inputs, inputs)\n",
    "    attention_output = layers.LayerNormalization(epsilon=1e-6)(attention_output + inputs)\n",
    "\n",
    "    # Feedforward Layer\n",
    "    ff_output = layers.Dense(128, activation='relu')(attention_output)\n",
    "    ff_output = layers.Dense(input_shape[1])(ff_output)\n",
    "    ff_output = layers.LayerNormalization(epsilon=1e-6)(ff_output + attention_output)\n",
    "\n",
    "    # Output Layer\n",
    "    output = layers.Dense(1, activation='sigmoid')(ff_output)\n",
    "\n",
    "    model = models.Model(inputs, output, name='transformer_attention_model')\n",
    "    return model\n",
    "\n",
    "# Create and compile the model\n",
    "transformer_model = transformer_attention_model(input_shape=(features.shape[1],))\n",
    "transformer_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', recall, precision, f1_score, auc])\n",
    "\n",
    "# Train the model\n",
    "history = transformer_model.fit(features, target, epochs=20, batch_size=32 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras.metrics import AUC, Precision, Recall, F1Score\n",
    "\n",
    "# Define custom metrics\n",
    "recall = Recall()\n",
    "precision = Precision()\n",
    "f1_score = F1Score()\n",
    "auc = AUC()\n",
    "\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "  \n",
    "from tensorflow.keras.layers import MultiHeadAttention\n",
    "\n",
    "tf.expand_dims\n",
    "\n",
    "\n",
    "# Define attention layer\n",
    "class GlobalAttention(layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(GlobalAttention, self).__init__()\n",
    "        self.units = units\n",
    "        self.W = layers.Dense(units)\n",
    "        #tf.print(self.units)\n",
    "        #tf.print(self.W)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Get the last hidden state\n",
    "        #print(inputs)\n",
    "        hidden_state = inputs[-1]\n",
    "        # Expand dimension to make it compatible with GlobalAttention\n",
    "        hidden_state = tf.expand_dims(hidden_state, axis=1)\n",
    "        #tf.print(hidden_state)\n",
    "        # Compute attention weights\n",
    "        attention_weights = tf.nn.softmax(tf.matmul(self.W(hidden_state), tf.transpose(inputs)))\n",
    "        #tf.print(attention_weights)\n",
    "        # Compute context vector\n",
    "        context_vector = tf.matmul(attention_weights, inputs)\n",
    "        #tf.print(context_vector)\n",
    "        # Concatenate context vector with hidden state\n",
    "        return tf.concat([context_vector, hidden_state], axis=-1)\n",
    "    \n",
    "# Build the MLP model\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(features.shape[1],)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    GlobalAttention(64),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "#model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\" ])\n",
    "\n",
    "\n",
    "# Compile the model with AdamW optimizer\n",
    "optimizer = AdamW(learning_rate=0.001)  # Use AdamW optimizer with a lower learning rate \n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "print(\"\\nfeatures shape: {}   and dType: {}\".format(features.shape, features.dtype))\n",
    "print(\"target shape: {}   and dType: {}\".format(target.shape, target.dtype)) \n",
    "print(\"\\n\")\n",
    "model.summary()\n",
    "# Train the model\n",
    "#model.fit(features, target, epochs=10 )\n",
    "model.fit(features, target, epochs=10, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "#model.evaluate(features, y_test_scaler)\n",
    "# Make predictions\n",
    "#predictions = model.predict(features)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the evaluate method\n",
    "y_test_float64 = np.asarray(y_test).astype('float64').reshape((-1,1))  #data['CoronaryHeartDisease']\n",
    "\n",
    "loss, accuracy, recall_value, precision_value, f1_score_value, auc_value = model.evaluate(X_test_scaler, y_test_float64)\n",
    "\n",
    "# Print the results\n",
    "print('Test loss: {}'.format(loss))\n",
    "print('Test accuracy: {}'.format(accuracy))\n",
    "print('Test recall: {}'.format(recall_value))\n",
    "print('Test precision: {}'.format(precision_value))\n",
    "print('Test F1 score: {}'.format(f1_score_value))\n",
    "print('Test AUC: {}'.format(auc_value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test_scaler)\n",
    "binary_predictions = predictions > 0.5 if 1 else 0\n",
    " \n",
    "display = ConfusionMatrixDisplay.from_predictions(y_test, binary_predictions, display_labels=['Healthy', 'Heart Disease'], cmap=mplot.cm.Blues)\n",
    "\n",
    "\n",
    "#display = ConfusionMatrixDisplay.from_estimator(model, X_test_scaler, y_test, display_labels=['Healthy', \"Heart Disease\"], cmap=mplot.cm.Blues) #, normalize=\"true\"\n",
    "method = \"Multi-Layer Perceptron\"\n",
    "display.ax_.set_title(\"Results {} Model\".format(method))\n",
    "display.ax_.set_xlabel('\\nPredicted Values')\n",
    "display.ax_.set_ylabel('Actual Values ')\n",
    "\n",
    "accuracyString =\"Accuracy {}: {:.2f}\".format(method, accuracy*100.0 ) \n",
    "recallString =  'Recall {}: {:.2f}'.format(method, recall_value* 100.0)\n",
    "precisionString = 'Precision {}: {:.2f}'.format(method, precision_value * 100.0) \n",
    "dataSetString = \"F1 Score: {}\".format(f1_score_value)\n",
    "featureListString = \"AUC Score: {}\".format(auc_value)\n",
    "\n",
    "display.figure_.text(0.010, -0.05,  accuracyString, horizontalalignment='left', wrap=False )  \n",
    "display.figure_.text(0.010, -0.09,  recallString, horizontalalignment='left', wrap=False )      \n",
    "display.figure_.text(0.010, -0.13,  precisionString, horizontalalignment='left', wrap=False ) \n",
    "display.figure_.text(0.010, -0.17,  dataSetString, horizontalalignment='left', wrap=False ) \n",
    "display.figure_.text(0.010, -0.28,  featureListString, horizontalalignment='left', wrap=False ) \n",
    " \n",
    "picturePath = \"{}Model_Evaluation_{}_{}.png\".format(dataSetResultDirectory, method, dataSetName)\n",
    "mplot.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "print(\"{} Confusion Matrix saved:: path: {}\".format(method, picturePath))\n",
    "\n",
    "mplot.show()\n",
    "mplot.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot accuracy\n",
    "plt.plot(history.history['accuracy'], label='Train accuracy')\n",
    "#plt.plot(history.history['val_accuracy'], label='Val accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "# Add additional metrics and labels\n",
    "metrics = ['loss', 'recall', 'precision', 'f1_score', 'auc']\n",
    "for metric in metrics:\n",
    "    ax2 = plt.twinx()\n",
    "    plt.plot(history.history[metric], label=metric.capitalize(), ax=ax2)\n",
    "    ax2.set_ylabel(metric.capitalize(), labelpad=10)\n",
    "    ax2.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Adjust layout\n",
    "plt.subplots_adjust(right=0.75)\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Save and clear plot\n",
    "picturePath = \"{}Confusion_Matrix_{}_{}.png\".format(dataSetResultDirectory, \"RNN Model\", dataSetName)\n",
    "plt.savefig(picturePath, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot accuracy\n",
    "plt.plot(history.history['accuracy'], label='Train accuracy')\n",
    "#plt.plot(history.history['val_accuracy'], label='Val accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "# Add additional metrics and adjust label positions\n",
    "metrics = ['loss', 'recall', 'precision', 'f1_score', 'auc']\n",
    "for i, metric in enumerate(metrics):\n",
    "    plt.plot(history.history[metric], label=metric.capitalize())\n",
    "    y_offset = (i - 2) * 0.1  # Adjust based on desired spacing\n",
    "    plt.text(1, 1 - y_offset, metric.capitalize(), verticalalignment='top', ha='right', transform=plt.gca().transAxes)\n",
    "\n",
    "# Adjust layout and legend\n",
    "plt.subplots_adjust(right=0.75)\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Save and clear plot\n",
    "picturePath = \"{}Result_Matrix2_{}_{}.png\".format(dataSetResultDirectory, \"RNN Model\", dataSetName)\n",
    "plt.savefig(picturePath, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "#plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'])\n",
    "\n",
    "picturePath = \"{}Confusion_Matrix_{}_{}.png\".format(dataSetResultDirectory, \"RNN Model\", dataSetName)\n",
    "plt.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "currentDateTime = datetime.datetime.now() \n",
    "currentDateTime = currentDateTime.strftime(\"%Y%m%d %H%M\") \n",
    "modelPath = \"{}model1_trained_{}_{}_{}percent.model\".format(dataSetResultDirectory, dataSetName, currentDateTime, accuracy)\n",
    "print(modelPath)\n",
    "model.save(modelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
